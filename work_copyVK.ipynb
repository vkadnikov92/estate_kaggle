{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost\n",
    "\n",
    "# from functions import col_analytics, get_score, res_2_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Внутренние функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_column(df_column, threshold):\n",
    "    value_counts = df_column.value_counts(normalize=True)\n",
    "    recoded_column = df_column.apply(lambda x: 1 if value_counts[x] >= threshold else 0)\n",
    "    return recoded_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_analytics(col, normalize=None):\n",
    "    print(f'Число NaN: {subm_df[col].isna().sum()}')\n",
    "    print(f'Число уникальный значений: {subm_df[col].nunique()}')\n",
    "    print(subm_df[col].value_counts(normalize=normalize))\n",
    "    sns.histplot(subm_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_category(column, threshold, df):\n",
    "    # Calculate the frequency of each category\n",
    "    value_counts = df[column].value_counts(normalize=True)\n",
    "    \n",
    "    # Recode values below the threshold to \"Other\"\n",
    "    df[column] = df[column].apply(lambda x: x if value_counts[x] >= threshold else 'Other')  \n",
    "    return df[column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv('data/test.csv')\n",
    "subm_df=pd.concat([df,test],axis=0)\n",
    "subm_df.drop('SalePrice', axis=1, inplace=True)\n",
    "y_train=df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 81), (1459, 80), (2919, 80))"
      ]
     },
     "execution_count": 1053,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, test.shape, subm_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "График цены ниже показывает, что следует модель строить для логарифмированной цены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_num = subm_df.select_dtypes(include = ['float64', 'int64', 'int8'])\n",
    "# df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем удалять те параметры, где \"перекос\" в сторону конкретной категории / значения составляет более 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_cat is a DataFrame containing your categorical variables\n",
    "# df_cat = subm_df.select_dtypes(include = ['object'])\n",
    "\n",
    "# # Get the number of categorical columns\n",
    "# num_cols = df_cat.shape[1]\n",
    "\n",
    "# # Calculate the number of rows and columns for the subplot grid\n",
    "# num_rows = (num_cols - 1) // 5 + 1\n",
    "# num_cols = min(num_cols, 5)\n",
    "\n",
    "# # Create a figure with subplots\n",
    "# fig, axs = plt.subplots(num_rows, num_cols, figsize=(5*num_cols, 4*num_rows))\n",
    "\n",
    "# # Flatten the axs array if it's 2D\n",
    "# if num_rows > 1:\n",
    "#     axs = axs.ravel()\n",
    "\n",
    "# # Plot countplots for each categorical variable\n",
    "# for i, col in enumerate(df_cat.columns):\n",
    "#     sns.countplot(x=col, data=df_cat, ax=axs[i])\n",
    "#     axs[i].set_title(f'Countplot of {col}')\n",
    "#     axs[i].set_xlabel(col)\n",
    "#     axs[i].set_ylabel('Count')\n",
    "\n",
    "# # Remove any empty subplots\n",
    "# for i in range(len(df_cat.columns), len(axs)):\n",
    "#     axs[i].axis('off')\n",
    "\n",
    "# # Adjust the layout to prevent overlap of labels\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Show the plots\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично, будем удалять те фичи, где \"перекос\" в сторону конкретной категории / значения составляет более 85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_cols = subm_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Id': 0,\n",
       " 'MSSubClass': 0,\n",
       " 'MSZoning': 4,\n",
       " 'LotFrontage': 486,\n",
       " 'LotArea': 0,\n",
       " 'Street': 0,\n",
       " 'Alley': 2721,\n",
       " 'LotShape': 0,\n",
       " 'LandContour': 0,\n",
       " 'Utilities': 2,\n",
       " 'LotConfig': 0,\n",
       " 'LandSlope': 0,\n",
       " 'Neighborhood': 0,\n",
       " 'Condition1': 0,\n",
       " 'Condition2': 0,\n",
       " 'BldgType': 0,\n",
       " 'HouseStyle': 0,\n",
       " 'OverallQual': 0,\n",
       " 'OverallCond': 0,\n",
       " 'YearBuilt': 0,\n",
       " 'YearRemodAdd': 0,\n",
       " 'RoofStyle': 0,\n",
       " 'RoofMatl': 0,\n",
       " 'Exterior1st': 1,\n",
       " 'Exterior2nd': 1,\n",
       " 'MasVnrType': 1766,\n",
       " 'MasVnrArea': 23,\n",
       " 'ExterQual': 0,\n",
       " 'ExterCond': 0,\n",
       " 'Foundation': 0,\n",
       " 'BsmtQual': 81,\n",
       " 'BsmtCond': 82,\n",
       " 'BsmtExposure': 82,\n",
       " 'BsmtFinType1': 79,\n",
       " 'BsmtFinSF1': 1,\n",
       " 'BsmtFinType2': 80,\n",
       " 'BsmtFinSF2': 1,\n",
       " 'BsmtUnfSF': 1,\n",
       " 'TotalBsmtSF': 1,\n",
       " 'Heating': 0,\n",
       " 'HeatingQC': 0,\n",
       " 'CentralAir': 0,\n",
       " 'Electrical': 1,\n",
       " '1stFlrSF': 0,\n",
       " '2ndFlrSF': 0,\n",
       " 'LowQualFinSF': 0,\n",
       " 'GrLivArea': 0,\n",
       " 'BsmtFullBath': 2,\n",
       " 'BsmtHalfBath': 2,\n",
       " 'FullBath': 0,\n",
       " 'HalfBath': 0,\n",
       " 'BedroomAbvGr': 0,\n",
       " 'KitchenAbvGr': 0,\n",
       " 'KitchenQual': 1,\n",
       " 'TotRmsAbvGrd': 0,\n",
       " 'Functional': 2,\n",
       " 'Fireplaces': 0,\n",
       " 'FireplaceQu': 1420,\n",
       " 'GarageType': 157,\n",
       " 'GarageYrBlt': 159,\n",
       " 'GarageFinish': 159,\n",
       " 'GarageCars': 1,\n",
       " 'GarageArea': 1,\n",
       " 'GarageQual': 159,\n",
       " 'GarageCond': 159,\n",
       " 'PavedDrive': 0,\n",
       " 'WoodDeckSF': 0,\n",
       " 'OpenPorchSF': 0,\n",
       " 'EnclosedPorch': 0,\n",
       " '3SsnPorch': 0,\n",
       " 'ScreenPorch': 0,\n",
       " 'PoolArea': 0,\n",
       " 'PoolQC': 2909,\n",
       " 'Fence': 2348,\n",
       " 'MiscFeature': 2814,\n",
       " 'MiscVal': 0,\n",
       " 'MoSold': 0,\n",
       " 'YrSold': 0,\n",
       " 'SaleType': 1,\n",
       " 'SaleCondition': 0}"
      ]
     },
     "execution_count": 1057,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_df.isna().sum().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем ненужные фичи (много пропусков, слишком большое смещение 85%+ в одну категорию), далее будем разбираться с nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsmt_qual_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
    "subm_df['BsmtQual'] = subm_df['BsmtQual'].map(bsmt_qual_mapping)\n",
    "exter_qual_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n",
    "subm_df['ExterQual'] = subm_df['ExterQual'].map(exter_qual_mapping)\n",
    "exter_cond_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n",
    "subm_df['ExterCond'] = subm_df['ExterCond'].map(exter_cond_mapping)\n",
    "heating_qc_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n",
    "subm_df['HeatingQC'] = subm_df['HeatingQC'].map(heating_qc_mapping)\n",
    "subm_df['LotFrontage']=subm_df['LotFrontage'].fillna(subm_df['LotFrontage'].mean())\n",
    "subm_df['BsmtQual']=subm_df['BsmtQual'].fillna(subm_df['BsmtQual'].mode()[0])\n",
    "subm_df.drop(['Street', 'Alley', 'Utilities', 'LandSlope', 'Condition2', 'RoofMatl', 'Neighborhood', 'Heating'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "columns_to_transform = ['MSZoning', 'LotShape', 'LandContour', 'LotConfig', 'Condition1', 'BldgType',\n",
    "                        'RoofStyle', 'MasVnrArea', 'BsmtCond', 'BsmtExposure', 'BsmtFinType2', 'BsmtFinSF2']\n",
    "for col in columns_to_transform:\n",
    "    most_frequent_value = subm_df[col].mode()[0]\n",
    "    subm_df[col] = subm_df[col].apply(lambda x: 1 if x == most_frequent_value else 0)\n",
    "\n",
    "\n",
    "\n",
    "columns_to_normalize = ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
    "                        'YearBuilt', 'YearRemodAdd', 'ExterQual', 'ExterCond', 'BsmtFinSF1',\n",
    "                        'BsmtUnfSF', 'TotalBsmtSF','BsmtQual']\n",
    "\n",
    "for col in columns_to_normalize:\n",
    "    subm_df[col] = (subm_df[col] - subm_df[col].min()) / (subm_df[col].max() - subm_df[col].min())\n",
    "\n",
    "columns_to_transform = ['HouseStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'BsmtFinType1']\n",
    "\n",
    "for column in columns_to_transform:\n",
    "    value_counts = df[column].value_counts()\n",
    "    most_popular_value = value_counts.index[0]\n",
    "    second_popular_value = value_counts.index[1]\n",
    "    subm_df[column] = subm_df[column].apply(lambda x: 2 if x == most_popular_value else (1 if x == second_popular_value else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 1059,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_2_delete = ['LowQualFinSF', '2ndFlrSF', 'BsmtHalfBath', 'Functional', 'WoodDeckSF', \n",
    "                'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal', 'CentralAir', 'Electrical', 'GarageQual', \n",
    "                'EnclosedPorch','3SsnPorch', 'ScreenPorch', 'KitchenAbvGr', 'SaleType', 'GarageCond', 'PavedDrive']\n",
    "\n",
    "# KeyError: \"['Street', 'Alley', 'Utilities', 'LandSlope', 'Condition2', 'RoofMatl', 'Neighborhood', 'Heating'] not found in axis\"\n",
    "len(col_2_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем колонки\n",
    "subm_df = subm_df.drop(columns=col_2_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_transform = ['HouseStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'BsmtFinType1']\n",
    "\n",
    "# for column in columns_to_transform:\n",
    "#     value_counts = df[column].value_counts()\n",
    "#     most_popular_value = value_counts.index[0]\n",
    "#     second_popular_value = value_counts.index[1]\n",
    "#     subm_df[column] = subm_df[column].apply(lambda x: 2 if x == most_popular_value else (1 if x == second_popular_value else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_2_reshape_2encoding = ['Fireplaces', 'FireplaceQu', 'HeatingQC', 'BsmtFullBath', 'KitchenQual', \n",
    "'GarageCars', 'PavedDrive', 'OpenPorchSF', 'WoodDeckSF', 'HalfBath', 'SaleCondition']\n",
    "\n",
    "col_2_encoding = ['GarageType', 'GarageFinish', 'MoSold', 'YrSold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация и перекодирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df['SaleCondition'] = recode_category('SaleCondition', 0.05, subm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.col_analytics(col, normalize=None)>"
      ]
     },
     "execution_count": 1064,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Normal\n",
       "1        Normal\n",
       "2        Normal\n",
       "3       Abnorml\n",
       "4        Normal\n",
       "5        Normal\n",
       "6        Normal\n",
       "7        Normal\n",
       "8       Abnorml\n",
       "9        Normal\n",
       "10       Normal\n",
       "11      Partial\n",
       "12       Normal\n",
       "13      Partial\n",
       "14       Normal\n",
       "15       Normal\n",
       "16       Normal\n",
       "17       Normal\n",
       "18       Normal\n",
       "19      Abnorml\n",
       "20      Partial\n",
       "21       Normal\n",
       "22       Normal\n",
       "23       Normal\n",
       "24       Normal\n",
       "25       Normal\n",
       "26       Normal\n",
       "27       Normal\n",
       "28       Normal\n",
       "29       Normal\n",
       "30       Normal\n",
       "31       Normal\n",
       "32       Normal\n",
       "33       Normal\n",
       "34       Normal\n",
       "35       Normal\n",
       "36       Normal\n",
       "37       Normal\n",
       "38      Abnorml\n",
       "39        Other\n",
       "40      Abnorml\n",
       "41       Normal\n",
       "42       Normal\n",
       "43       Normal\n",
       "44       Normal\n",
       "45       Normal\n",
       "46      Abnorml\n",
       "47       Normal\n",
       "48      Partial\n",
       "49       Normal\n",
       "50       Normal\n",
       "51       Normal\n",
       "52       Normal\n",
       "53       Normal\n",
       "54       Normal\n",
       "55       Normal\n",
       "56      Abnorml\n",
       "57       Normal\n",
       "58      Partial\n",
       "59       Normal\n",
       "60      Partial\n",
       "61       Normal\n",
       "62       Normal\n",
       "63       Normal\n",
       "64       Normal\n",
       "65       Normal\n",
       "66       Normal\n",
       "67       Normal\n",
       "68       Normal\n",
       "69       Normal\n",
       "70       Normal\n",
       "71       Normal\n",
       "72       Normal\n",
       "73       Normal\n",
       "74       Normal\n",
       "75       Normal\n",
       "76       Normal\n",
       "77       Normal\n",
       "78       Normal\n",
       "79       Normal\n",
       "80       Normal\n",
       "81       Normal\n",
       "82       Normal\n",
       "83       Normal\n",
       "84       Normal\n",
       "85       Normal\n",
       "86       Normal\n",
       "87      Partial\n",
       "88      Abnorml\n",
       "89       Normal\n",
       "90       Normal\n",
       "91      Abnorml\n",
       "92       Normal\n",
       "93       Normal\n",
       "94       Normal\n",
       "95       Normal\n",
       "96       Normal\n",
       "97       Normal\n",
       "98      Abnorml\n",
       "99       Normal\n",
       "100      Normal\n",
       "101      Normal\n",
       "102       Other\n",
       "103      Normal\n",
       "104      Normal\n",
       "105      Normal\n",
       "106      Normal\n",
       "107     Partial\n",
       "108      Normal\n",
       "109      Normal\n",
       "110      Normal\n",
       "111      Normal\n",
       "112     Partial\n",
       "113     Abnorml\n",
       "114      Normal\n",
       "115      Normal\n",
       "116      Normal\n",
       "117     Partial\n",
       "118      Normal\n",
       "119     Partial\n",
       "120      Normal\n",
       "121      Normal\n",
       "122      Normal\n",
       "123      Normal\n",
       "124      Normal\n",
       "125      Normal\n",
       "126      Normal\n",
       "127      Normal\n",
       "128      Normal\n",
       "129     Abnorml\n",
       "130      Normal\n",
       "131      Normal\n",
       "132      Normal\n",
       "133      Normal\n",
       "134      Normal\n",
       "135      Normal\n",
       "136      Normal\n",
       "137       Other\n",
       "138      Normal\n",
       "139      Normal\n",
       "140      Normal\n",
       "141      Normal\n",
       "142      Normal\n",
       "143      Normal\n",
       "144     Abnorml\n",
       "145      Normal\n",
       "146      Normal\n",
       "147      Normal\n",
       "148      Normal\n",
       "149      Normal\n",
       "150      Normal\n",
       "151     Partial\n",
       "152      Normal\n",
       "153      Normal\n",
       "154       Other\n",
       "155      Normal\n",
       "156      Normal\n",
       "157     Partial\n",
       "158      Normal\n",
       "159     Partial\n",
       "160      Normal\n",
       "161      Normal\n",
       "162     Partial\n",
       "163      Normal\n",
       "164      Normal\n",
       "165      Normal\n",
       "166      Normal\n",
       "167     Partial\n",
       "168      Normal\n",
       "169      Normal\n",
       "170      Normal\n",
       "171      Normal\n",
       "172      Normal\n",
       "173      Normal\n",
       "174      Normal\n",
       "175      Normal\n",
       "176      Normal\n",
       "177      Normal\n",
       "178     Partial\n",
       "179      Normal\n",
       "180      Normal\n",
       "181      Normal\n",
       "182      Normal\n",
       "183      Normal\n",
       "184      Normal\n",
       "185      Normal\n",
       "186      Normal\n",
       "187      Normal\n",
       "188       Other\n",
       "189      Normal\n",
       "190      Normal\n",
       "191      Normal\n",
       "192      Normal\n",
       "193      Normal\n",
       "194      Normal\n",
       "195      Normal\n",
       "196     Partial\n",
       "197     Abnorml\n",
       "198     Abnorml\n",
       "199      Normal\n",
       "200      Normal\n",
       "201      Normal\n",
       "202      Normal\n",
       "203      Normal\n",
       "204      Normal\n",
       "205      Normal\n",
       "206      Normal\n",
       "207      Normal\n",
       "208      Normal\n",
       "209      Normal\n",
       "210      Normal\n",
       "211      Normal\n",
       "212     Partial\n",
       "213      Normal\n",
       "214      Normal\n",
       "215      Normal\n",
       "216      Normal\n",
       "217       Other\n",
       "218      Normal\n",
       "219     Partial\n",
       "220     Partial\n",
       "221      Normal\n",
       "222      Normal\n",
       "223     Abnorml\n",
       "224      Normal\n",
       "225     Abnorml\n",
       "226     Abnorml\n",
       "227      Normal\n",
       "228      Normal\n",
       "229      Normal\n",
       "230      Normal\n",
       "231      Normal\n",
       "232      Normal\n",
       "233      Normal\n",
       "234      Normal\n",
       "235      Normal\n",
       "236      Normal\n",
       "237      Normal\n",
       "238     Partial\n",
       "239      Normal\n",
       "240      Normal\n",
       "241      Normal\n",
       "242      Normal\n",
       "243      Normal\n",
       "244      Normal\n",
       "245      Normal\n",
       "246      Normal\n",
       "247      Normal\n",
       "248      Normal\n",
       "249      Normal\n",
       "250      Normal\n",
       "251       Other\n",
       "252      Normal\n",
       "253      Normal\n",
       "254      Normal\n",
       "255      Normal\n",
       "256      Normal\n",
       "257     Abnorml\n",
       "258      Normal\n",
       "259      Normal\n",
       "260      Normal\n",
       "261     Partial\n",
       "262      Normal\n",
       "263      Normal\n",
       "264      Normal\n",
       "265      Normal\n",
       "266      Normal\n",
       "267      Normal\n",
       "268      Normal\n",
       "269      Normal\n",
       "270     Partial\n",
       "271      Normal\n",
       "272      Normal\n",
       "273      Normal\n",
       "274      Normal\n",
       "275      Normal\n",
       "276      Normal\n",
       "277      Normal\n",
       "278     Partial\n",
       "279      Normal\n",
       "280      Normal\n",
       "281     Partial\n",
       "282      Normal\n",
       "283     Partial\n",
       "284      Normal\n",
       "285     Partial\n",
       "286      Normal\n",
       "287      Normal\n",
       "288      Normal\n",
       "289      Normal\n",
       "290     Partial\n",
       "291      Normal\n",
       "292      Normal\n",
       "293      Normal\n",
       "294      Normal\n",
       "295      Normal\n",
       "296      Normal\n",
       "297      Normal\n",
       "298      Normal\n",
       "299       Other\n",
       "300      Normal\n",
       "301      Normal\n",
       "302      Normal\n",
       "303     Abnorml\n",
       "304      Normal\n",
       "305      Normal\n",
       "306      Normal\n",
       "307      Normal\n",
       "308      Normal\n",
       "309      Normal\n",
       "310      Normal\n",
       "311      Normal\n",
       "312      Normal\n",
       "313      Normal\n",
       "314      Normal\n",
       "315      Normal\n",
       "316      Normal\n",
       "317      Normal\n",
       "318      Normal\n",
       "319      Normal\n",
       "320     Partial\n",
       "321      Normal\n",
       "322      Normal\n",
       "323      Normal\n",
       "324      Normal\n",
       "325      Normal\n",
       "326      Normal\n",
       "327      Normal\n",
       "328      Normal\n",
       "329      Normal\n",
       "330      Normal\n",
       "331      Normal\n",
       "332      Normal\n",
       "333      Normal\n",
       "334      Normal\n",
       "335      Normal\n",
       "336      Normal\n",
       "337      Normal\n",
       "338      Normal\n",
       "339      Normal\n",
       "340      Normal\n",
       "341      Normal\n",
       "342      Normal\n",
       "343      Normal\n",
       "344      Normal\n",
       "345      Normal\n",
       "346      Normal\n",
       "347      Normal\n",
       "348      Normal\n",
       "349     Partial\n",
       "350     Partial\n",
       "351     Abnorml\n",
       "352      Normal\n",
       "353      Normal\n",
       "354      Normal\n",
       "355      Normal\n",
       "356      Normal\n",
       "357      Normal\n",
       "358     Abnorml\n",
       "359      Normal\n",
       "360      Normal\n",
       "361      Normal\n",
       "362      Normal\n",
       "363      Normal\n",
       "364      Normal\n",
       "365      Normal\n",
       "366      Normal\n",
       "367      Normal\n",
       "368      Normal\n",
       "369      Normal\n",
       "370      Normal\n",
       "371      Normal\n",
       "372      Normal\n",
       "373      Normal\n",
       "374      Normal\n",
       "375      Normal\n",
       "376      Normal\n",
       "377      Normal\n",
       "378     Partial\n",
       "379      Normal\n",
       "380      Normal\n",
       "381     Partial\n",
       "382      Normal\n",
       "383      Normal\n",
       "384      Normal\n",
       "385      Normal\n",
       "386       Other\n",
       "387     Abnorml\n",
       "388      Normal\n",
       "389     Partial\n",
       "390      Normal\n",
       "391      Normal\n",
       "392      Normal\n",
       "393     Abnorml\n",
       "394      Normal\n",
       "395      Normal\n",
       "396      Normal\n",
       "397      Normal\n",
       "398     Abnorml\n",
       "399      Normal\n",
       "400      Normal\n",
       "401     Partial\n",
       "402      Normal\n",
       "403     Abnorml\n",
       "404      Normal\n",
       "405      Normal\n",
       "406      Normal\n",
       "407      Normal\n",
       "408     Partial\n",
       "409     Partial\n",
       "410     Abnorml\n",
       "411      Normal\n",
       "412     Partial\n",
       "413      Normal\n",
       "414      Normal\n",
       "415     Partial\n",
       "416      Normal\n",
       "417      Normal\n",
       "418       Other\n",
       "419      Normal\n",
       "420       Other\n",
       "421      Normal\n",
       "422      Normal\n",
       "423      Normal\n",
       "424      Normal\n",
       "425      Normal\n",
       "426      Normal\n",
       "427      Normal\n",
       "428     Partial\n",
       "429      Normal\n",
       "430     Abnorml\n",
       "431     Abnorml\n",
       "432      Normal\n",
       "433      Normal\n",
       "434      Normal\n",
       "435      Normal\n",
       "436      Normal\n",
       "437      Normal\n",
       "438      Normal\n",
       "439      Normal\n",
       "440      Normal\n",
       "441      Normal\n",
       "442      Normal\n",
       "443     Partial\n",
       "444      Normal\n",
       "445      Normal\n",
       "446      Normal\n",
       "447      Normal\n",
       "448      Normal\n",
       "449      Normal\n",
       "450      Normal\n",
       "451      Normal\n",
       "452      Normal\n",
       "453      Normal\n",
       "454       Other\n",
       "455      Normal\n",
       "456     Abnorml\n",
       "457      Normal\n",
       "458      Normal\n",
       "459      Normal\n",
       "460     Partial\n",
       "461      Normal\n",
       "462      Normal\n",
       "463      Normal\n",
       "464      Normal\n",
       "465      Normal\n",
       "466      Normal\n",
       "467      Normal\n",
       "468      Normal\n",
       "469      Normal\n",
       "470      Normal\n",
       "471      Normal\n",
       "472      Normal\n",
       "473     Partial\n",
       "474      Normal\n",
       "475      Normal\n",
       "476      Normal\n",
       "477      Normal\n",
       "478      Normal\n",
       "479       Other\n",
       "480      Normal\n",
       "481      Normal\n",
       "482      Normal\n",
       "483      Normal\n",
       "484      Normal\n",
       "485      Normal\n",
       "486      Normal\n",
       "487      Normal\n",
       "488      Normal\n",
       "489      Normal\n",
       "490      Normal\n",
       "491      Normal\n",
       "492     Partial\n",
       "493      Normal\n",
       "494      Normal\n",
       "495     Abnorml\n",
       "496      Normal\n",
       "497      Normal\n",
       "498      Normal\n",
       "499      Normal\n",
       "500      Normal\n",
       "501      Normal\n",
       "502      Normal\n",
       "503      Normal\n",
       "504      Normal\n",
       "505      Normal\n",
       "506      Normal\n",
       "507     Partial\n",
       "508      Normal\n",
       "509      Normal\n",
       "510      Normal\n",
       "511     Partial\n",
       "512      Normal\n",
       "513      Normal\n",
       "514      Normal\n",
       "515     Partial\n",
       "516     Abnorml\n",
       "517      Normal\n",
       "518      Normal\n",
       "519      Normal\n",
       "520      Normal\n",
       "521      Normal\n",
       "522      Normal\n",
       "523     Partial\n",
       "524      Normal\n",
       "525      Normal\n",
       "526      Normal\n",
       "527     Partial\n",
       "528      Normal\n",
       "529       Other\n",
       "530     Abnorml\n",
       "531      Normal\n",
       "532      Normal\n",
       "533      Normal\n",
       "534      Normal\n",
       "535      Normal\n",
       "536      Normal\n",
       "537      Normal\n",
       "538      Normal\n",
       "539      Normal\n",
       "540      Normal\n",
       "541      Normal\n",
       "542      Normal\n",
       "543      Normal\n",
       "544     Partial\n",
       "545      Normal\n",
       "546      Normal\n",
       "547      Normal\n",
       "548      Normal\n",
       "549      Normal\n",
       "550     Abnorml\n",
       "551      Normal\n",
       "552      Normal\n",
       "553      Normal\n",
       "554      Normal\n",
       "555      Normal\n",
       "556      Normal\n",
       "557      Normal\n",
       "558      Normal\n",
       "559      Normal\n",
       "560      Normal\n",
       "561      Normal\n",
       "562      Normal\n",
       "563      Normal\n",
       "564      Normal\n",
       "565      Normal\n",
       "566      Normal\n",
       "567      Normal\n",
       "568      Normal\n",
       "569      Normal\n",
       "570      Normal\n",
       "571     Abnorml\n",
       "572     Partial\n",
       "573      Normal\n",
       "574      Normal\n",
       "575     Abnorml\n",
       "576      Normal\n",
       "577     Abnorml\n",
       "578     Abnorml\n",
       "579      Normal\n",
       "580      Normal\n",
       "581     Partial\n",
       "582      Normal\n",
       "583      Normal\n",
       "584      Normal\n",
       "585     Partial\n",
       "586      Normal\n",
       "587      Normal\n",
       "588     Partial\n",
       "589      Normal\n",
       "590      Normal\n",
       "591      Normal\n",
       "592      Normal\n",
       "593      Normal\n",
       "594      Normal\n",
       "595     Partial\n",
       "596      Normal\n",
       "597     Partial\n",
       "598      Normal\n",
       "599      Normal\n",
       "600      Normal\n",
       "601      Normal\n",
       "602     Abnorml\n",
       "603      Normal\n",
       "604      Normal\n",
       "605      Normal\n",
       "606      Normal\n",
       "607      Normal\n",
       "608       Other\n",
       "609      Normal\n",
       "610      Normal\n",
       "611      Normal\n",
       "612      Normal\n",
       "613     Partial\n",
       "614      Normal\n",
       "615     Abnorml\n",
       "616      Normal\n",
       "617      Normal\n",
       "618     Partial\n",
       "619      Normal\n",
       "620      Normal\n",
       "621      Normal\n",
       "622      Normal\n",
       "623      Normal\n",
       "624      Normal\n",
       "625      Normal\n",
       "626      Normal\n",
       "627      Normal\n",
       "628       Other\n",
       "629      Normal\n",
       "630     Abnorml\n",
       "631      Normal\n",
       "632       Other\n",
       "633      Normal\n",
       "634      Normal\n",
       "635     Abnorml\n",
       "636      Normal\n",
       "637      Normal\n",
       "638      Normal\n",
       "639     Partial\n",
       "640      Normal\n",
       "641      Normal\n",
       "642      Normal\n",
       "643      Normal\n",
       "644     Partial\n",
       "645      Normal\n",
       "646      Normal\n",
       "647      Normal\n",
       "648      Normal\n",
       "649      Normal\n",
       "650      Normal\n",
       "651      Normal\n",
       "652      Normal\n",
       "653      Normal\n",
       "654      Normal\n",
       "655       Other\n",
       "656      Normal\n",
       "657      Normal\n",
       "658     Abnorml\n",
       "659      Normal\n",
       "660      Normal\n",
       "661      Normal\n",
       "662      Normal\n",
       "663      Normal\n",
       "664     Partial\n",
       "665      Normal\n",
       "666     Abnorml\n",
       "667      Normal\n",
       "668      Normal\n",
       "669      Normal\n",
       "670      Normal\n",
       "671      Normal\n",
       "672      Normal\n",
       "673      Normal\n",
       "674      Normal\n",
       "675      Normal\n",
       "676      Normal\n",
       "677      Normal\n",
       "678     Partial\n",
       "679      Normal\n",
       "680      Normal\n",
       "681     Abnorml\n",
       "682      Normal\n",
       "683      Normal\n",
       "684      Normal\n",
       "685      Normal\n",
       "686     Partial\n",
       "687      Normal\n",
       "688     Partial\n",
       "689      Normal\n",
       "690      Normal\n",
       "691      Normal\n",
       "692      Normal\n",
       "693     Abnorml\n",
       "694      Normal\n",
       "695      Normal\n",
       "696      Normal\n",
       "697      Normal\n",
       "698      Normal\n",
       "699      Normal\n",
       "700      Normal\n",
       "701      Normal\n",
       "702     Partial\n",
       "703      Normal\n",
       "704      Normal\n",
       "705      Normal\n",
       "706      Normal\n",
       "707      Normal\n",
       "708     Partial\n",
       "709     Abnorml\n",
       "710      Normal\n",
       "711     Abnorml\n",
       "712      Normal\n",
       "713      Normal\n",
       "714      Normal\n",
       "715      Normal\n",
       "716      Normal\n",
       "717      Normal\n",
       "718      Normal\n",
       "719      Normal\n",
       "720      Normal\n",
       "721      Normal\n",
       "722      Normal\n",
       "723      Normal\n",
       "724      Normal\n",
       "725      Normal\n",
       "726      Normal\n",
       "727      Normal\n",
       "728     Abnorml\n",
       "729      Normal\n",
       "730      Normal\n",
       "731      Normal\n",
       "732      Normal\n",
       "733      Normal\n",
       "734       Other\n",
       "735      Normal\n",
       "736      Normal\n",
       "737      Normal\n",
       "738       Other\n",
       "739      Normal\n",
       "740     Abnorml\n",
       "741      Normal\n",
       "742      Normal\n",
       "743      Normal\n",
       "744      Normal\n",
       "745      Normal\n",
       "746      Normal\n",
       "747      Normal\n",
       "748      Normal\n",
       "749      Normal\n",
       "750      Normal\n",
       "751      Normal\n",
       "752      Normal\n",
       "753      Normal\n",
       "754      Normal\n",
       "755      Normal\n",
       "756      Normal\n",
       "757     Abnorml\n",
       "758      Normal\n",
       "759      Normal\n",
       "760      Normal\n",
       "761      Normal\n",
       "762      Normal\n",
       "763      Normal\n",
       "764      Normal\n",
       "765     Partial\n",
       "766      Normal\n",
       "767      Normal\n",
       "768      Normal\n",
       "769      Normal\n",
       "770      Normal\n",
       "771      Normal\n",
       "772     Abnorml\n",
       "773      Normal\n",
       "774     Partial\n",
       "775      Normal\n",
       "776     Partial\n",
       "777      Normal\n",
       "778      Normal\n",
       "779      Normal\n",
       "780      Normal\n",
       "781      Normal\n",
       "782      Normal\n",
       "783      Normal\n",
       "784      Normal\n",
       "785      Normal\n",
       "786      Normal\n",
       "787      Normal\n",
       "788      Normal\n",
       "789      Normal\n",
       "790      Normal\n",
       "791      Normal\n",
       "792      Normal\n",
       "793     Partial\n",
       "794      Normal\n",
       "795      Normal\n",
       "796      Normal\n",
       "797     Abnorml\n",
       "798     Partial\n",
       "799      Normal\n",
       "800      Normal\n",
       "801      Normal\n",
       "802      Normal\n",
       "803     Partial\n",
       "804       Other\n",
       "805     Partial\n",
       "806      Normal\n",
       "807      Normal\n",
       "808      Normal\n",
       "809      Normal\n",
       "810      Normal\n",
       "811      Normal\n",
       "812       Other\n",
       "813      Normal\n",
       "814      Normal\n",
       "815      Normal\n",
       "816      Normal\n",
       "817      Normal\n",
       "818      Normal\n",
       "819     Partial\n",
       "820      Normal\n",
       "821      Normal\n",
       "822       Other\n",
       "823      Normal\n",
       "824     Partial\n",
       "825     Partial\n",
       "826      Normal\n",
       "827      Normal\n",
       "828     Abnorml\n",
       "829      Normal\n",
       "830      Normal\n",
       "831      Normal\n",
       "832      Normal\n",
       "833      Normal\n",
       "834      Normal\n",
       "835      Normal\n",
       "836      Normal\n",
       "837      Normal\n",
       "838      Normal\n",
       "839      Normal\n",
       "840      Normal\n",
       "841      Normal\n",
       "842      Normal\n",
       "843      Normal\n",
       "844      Normal\n",
       "845      Normal\n",
       "846      Normal\n",
       "847      Normal\n",
       "848      Normal\n",
       "849      Normal\n",
       "850      Normal\n",
       "851      Normal\n",
       "852      Normal\n",
       "853      Normal\n",
       "854     Abnorml\n",
       "855      Normal\n",
       "856      Normal\n",
       "857      Normal\n",
       "858       Other\n",
       "859      Normal\n",
       "860      Normal\n",
       "861      Normal\n",
       "862      Normal\n",
       "863      Normal\n",
       "864     Partial\n",
       "865      Normal\n",
       "866     Partial\n",
       "867      Normal\n",
       "868      Normal\n",
       "869      Normal\n",
       "870      Normal\n",
       "871      Normal\n",
       "872      Normal\n",
       "873      Normal\n",
       "874     Abnorml\n",
       "875     Partial\n",
       "876      Normal\n",
       "877      Normal\n",
       "878      Normal\n",
       "879      Normal\n",
       "880      Normal\n",
       "881      Normal\n",
       "882      Normal\n",
       "883      Normal\n",
       "884      Normal\n",
       "885     Abnorml\n",
       "886       Other\n",
       "887      Normal\n",
       "888      Normal\n",
       "889      Normal\n",
       "890      Normal\n",
       "891      Normal\n",
       "892      Normal\n",
       "893      Normal\n",
       "894       Other\n",
       "895      Normal\n",
       "896     Abnorml\n",
       "897       Other\n",
       "898     Partial\n",
       "899      Normal\n",
       "900      Normal\n",
       "901      Normal\n",
       "902      Normal\n",
       "903     Partial\n",
       "904      Normal\n",
       "905      Normal\n",
       "906      Normal\n",
       "907      Normal\n",
       "908      Normal\n",
       "909      Normal\n",
       "910      Normal\n",
       "911      Normal\n",
       "912     Abnorml\n",
       "913      Normal\n",
       "914     Partial\n",
       "915      Normal\n",
       "916     Abnorml\n",
       "917      Normal\n",
       "918      Normal\n",
       "919      Normal\n",
       "920      Normal\n",
       "921      Normal\n",
       "922     Partial\n",
       "923      Normal\n",
       "924      Normal\n",
       "925     Abnorml\n",
       "926      Normal\n",
       "927      Normal\n",
       "928      Normal\n",
       "929      Normal\n",
       "930      Normal\n",
       "931      Normal\n",
       "932      Normal\n",
       "933      Normal\n",
       "934      Normal\n",
       "935      Normal\n",
       "936      Normal\n",
       "937      Normal\n",
       "938     Partial\n",
       "939      Normal\n",
       "940      Normal\n",
       "941      Normal\n",
       "942     Abnorml\n",
       "943      Normal\n",
       "944     Abnorml\n",
       "945      Normal\n",
       "946      Normal\n",
       "947      Normal\n",
       "948      Normal\n",
       "949      Normal\n",
       "950      Normal\n",
       "951     Abnorml\n",
       "952      Normal\n",
       "953      Normal\n",
       "954       Other\n",
       "955      Normal\n",
       "956      Normal\n",
       "957      Normal\n",
       "958      Normal\n",
       "959      Normal\n",
       "960      Normal\n",
       "961      Normal\n",
       "962      Normal\n",
       "963      Normal\n",
       "964      Normal\n",
       "965     Partial\n",
       "966      Normal\n",
       "967      Normal\n",
       "968     Abnorml\n",
       "969      Normal\n",
       "970     Abnorml\n",
       "971      Normal\n",
       "972      Normal\n",
       "973     Partial\n",
       "974      Normal\n",
       "975      Normal\n",
       "976      Normal\n",
       "977     Partial\n",
       "978     Abnorml\n",
       "979      Normal\n",
       "980      Normal\n",
       "981      Normal\n",
       "982      Normal\n",
       "983      Normal\n",
       "984      Normal\n",
       "985      Normal\n",
       "986      Normal\n",
       "987     Partial\n",
       "988      Normal\n",
       "989     Partial\n",
       "990      Normal\n",
       "991      Normal\n",
       "992      Normal\n",
       "993     Partial\n",
       "994      Normal\n",
       "995     Abnorml\n",
       "996      Normal\n",
       "997      Normal\n",
       "998      Normal\n",
       "999      Normal\n",
       "1000     Normal\n",
       "1001    Abnorml\n",
       "1002     Normal\n",
       "1003     Normal\n",
       "1004     Normal\n",
       "1005     Normal\n",
       "1006     Normal\n",
       "1007     Normal\n",
       "1008     Normal\n",
       "1009     Normal\n",
       "1010     Normal\n",
       "1011     Normal\n",
       "1012     Normal\n",
       "1013     Normal\n",
       "1014     Normal\n",
       "1015     Normal\n",
       "1016     Normal\n",
       "1017    Abnorml\n",
       "1018     Normal\n",
       "1019     Normal\n",
       "1020     Normal\n",
       "1021    Partial\n",
       "1022     Normal\n",
       "1023     Normal\n",
       "1024    Abnorml\n",
       "1025     Normal\n",
       "1026     Normal\n",
       "1027    Partial\n",
       "1028     Normal\n",
       "1029     Normal\n",
       "1030     Normal\n",
       "1031     Normal\n",
       "1032    Abnorml\n",
       "1033     Normal\n",
       "1034     Normal\n",
       "1035     Normal\n",
       "1036     Normal\n",
       "1037     Normal\n",
       "1038     Normal\n",
       "1039     Normal\n",
       "1040     Normal\n",
       "1041     Normal\n",
       "1042     Normal\n",
       "1043     Normal\n",
       "1044     Normal\n",
       "1045     Normal\n",
       "1046    Partial\n",
       "1047     Normal\n",
       "1048     Normal\n",
       "1049    Abnorml\n",
       "1050    Partial\n",
       "1051    Partial\n",
       "1052     Normal\n",
       "1053     Normal\n",
       "1054     Normal\n",
       "1055    Abnorml\n",
       "1056     Normal\n",
       "1057     Normal\n",
       "1058     Normal\n",
       "1059     Normal\n",
       "1060     Normal\n",
       "1061     Normal\n",
       "1062     Normal\n",
       "1063     Normal\n",
       "1064     Normal\n",
       "1065     Normal\n",
       "1066     Normal\n",
       "1067     Normal\n",
       "1068     Normal\n",
       "1069     Normal\n",
       "1070     Normal\n",
       "1071     Normal\n",
       "1072     Normal\n",
       "1073     Normal\n",
       "1074     Normal\n",
       "1075     Normal\n",
       "1076     Normal\n",
       "1077    Abnorml\n",
       "1078     Normal\n",
       "1079     Normal\n",
       "1080    Abnorml\n",
       "1081     Normal\n",
       "1082     Normal\n",
       "1083     Normal\n",
       "1084     Normal\n",
       "1085     Normal\n",
       "1086     Normal\n",
       "1087     Normal\n",
       "1088     Normal\n",
       "1089     Normal\n",
       "1090     Normal\n",
       "1091     Normal\n",
       "1092     Normal\n",
       "1093     Normal\n",
       "1094     Normal\n",
       "1095     Normal\n",
       "1096     Normal\n",
       "1097     Normal\n",
       "1098     Normal\n",
       "1099    Abnorml\n",
       "1100     Normal\n",
       "1101     Normal\n",
       "1102      Other\n",
       "1103     Normal\n",
       "1104     Normal\n",
       "1105     Normal\n",
       "1106     Normal\n",
       "1107    Partial\n",
       "1108    Abnorml\n",
       "1109     Normal\n",
       "1110     Normal\n",
       "1111     Normal\n",
       "1112     Normal\n",
       "1113     Normal\n",
       "1114     Normal\n",
       "1115    Partial\n",
       "1116     Normal\n",
       "1117     Normal\n",
       "1118     Normal\n",
       "1119     Normal\n",
       "1120     Normal\n",
       "1121    Partial\n",
       "1122    Abnorml\n",
       "1123     Normal\n",
       "1124     Normal\n",
       "1125     Normal\n",
       "1126     Normal\n",
       "1127      Other\n",
       "1128     Normal\n",
       "1129     Normal\n",
       "1130     Normal\n",
       "1131    Abnorml\n",
       "1132     Normal\n",
       "1133     Normal\n",
       "1134     Normal\n",
       "1135     Normal\n",
       "1136    Abnorml\n",
       "1137     Normal\n",
       "1138     Normal\n",
       "1139     Normal\n",
       "1140    Abnorml\n",
       "1141     Normal\n",
       "1142    Partial\n",
       "1143     Normal\n",
       "1144     Normal\n",
       "1145      Other\n",
       "1146     Normal\n",
       "1147     Normal\n",
       "1148     Normal\n",
       "1149     Normal\n",
       "1150     Normal\n",
       "1151     Normal\n",
       "1152    Abnorml\n",
       "1153     Normal\n",
       "1154     Normal\n",
       "1155     Normal\n",
       "1156     Normal\n",
       "1157     Normal\n",
       "1158    Partial\n",
       "1159     Normal\n",
       "1160     Normal\n",
       "1161     Normal\n",
       "1162     Normal\n",
       "1163      Other\n",
       "1164     Normal\n",
       "1165    Partial\n",
       "1166     Normal\n",
       "1167     Normal\n",
       "1168     Normal\n",
       "1169     Normal\n",
       "1170     Normal\n",
       "1171     Normal\n",
       "1172     Normal\n",
       "1173     Normal\n",
       "1174     Normal\n",
       "1175     Normal\n",
       "1176     Normal\n",
       "1177     Normal\n",
       "1178     Normal\n",
       "1179     Normal\n",
       "1180     Normal\n",
       "1181    Partial\n",
       "1182    Abnorml\n",
       "1183     Normal\n",
       "1184     Normal\n",
       "1185     Normal\n",
       "1186    Abnorml\n",
       "1187     Normal\n",
       "1188     Normal\n",
       "1189     Normal\n",
       "1190     Normal\n",
       "1191     Normal\n",
       "1192     Normal\n",
       "1193     Normal\n",
       "1194     Normal\n",
       "1195     Normal\n",
       "1196    Partial\n",
       "1197     Normal\n",
       "1198     Normal\n",
       "1199     Normal\n",
       "1200    Abnorml\n",
       "1201     Normal\n",
       "1202     Normal\n",
       "1203     Normal\n",
       "1204     Normal\n",
       "1205     Normal\n",
       "1206     Normal\n",
       "1207     Normal\n",
       "1208     Normal\n",
       "1209    Partial\n",
       "1210     Normal\n",
       "1211     Normal\n",
       "1212     Normal\n",
       "1213     Normal\n",
       "1214     Normal\n",
       "1215     Normal\n",
       "1216     Normal\n",
       "1217    Partial\n",
       "1218     Normal\n",
       "1219    Abnorml\n",
       "1220    Abnorml\n",
       "1221     Normal\n",
       "1222     Normal\n",
       "1223     Normal\n",
       "1224     Normal\n",
       "1225     Normal\n",
       "1226     Normal\n",
       "1227     Normal\n",
       "1228    Partial\n",
       "1229     Normal\n",
       "1230     Normal\n",
       "1231     Normal\n",
       "1232     Normal\n",
       "1233    Abnorml\n",
       "1234    Abnorml\n",
       "1235     Normal\n",
       "1236     Normal\n",
       "1237     Normal\n",
       "1238    Abnorml\n",
       "1239     Normal\n",
       "1240     Normal\n",
       "1241    Partial\n",
       "1242      Other\n",
       "1243    Partial\n",
       "1244     Normal\n",
       "1245    Abnorml\n",
       "1246    Partial\n",
       "1247     Normal\n",
       "1248     Normal\n",
       "1249     Normal\n",
       "1250     Normal\n",
       "1251     Normal\n",
       "1252     Normal\n",
       "1253     Normal\n",
       "1254     Normal\n",
       "1255     Normal\n",
       "1256     Normal\n",
       "1257     Normal\n",
       "1258     Normal\n",
       "1259     Normal\n",
       "1260     Normal\n",
       "1261     Normal\n",
       "1262     Normal\n",
       "1263     Normal\n",
       "1264    Abnorml\n",
       "1265     Normal\n",
       "1266     Normal\n",
       "1267     Normal\n",
       "1268     Normal\n",
       "1269     Normal\n",
       "1270     Normal\n",
       "1271     Normal\n",
       "1272     Normal\n",
       "1273     Normal\n",
       "1274     Normal\n",
       "1275     Normal\n",
       "1276     Normal\n",
       "1277     Normal\n",
       "1278     Normal\n",
       "1279    Abnorml\n",
       "1280     Normal\n",
       "1281     Normal\n",
       "1282     Normal\n",
       "1283     Normal\n",
       "1284     Normal\n",
       "1285     Normal\n",
       "1286     Normal\n",
       "1287     Normal\n",
       "1288     Normal\n",
       "1289    Partial\n",
       "1290     Normal\n",
       "1291     Normal\n",
       "1292     Normal\n",
       "1293     Normal\n",
       "1294     Normal\n",
       "1295     Normal\n",
       "1296     Normal\n",
       "1297    Partial\n",
       "1298    Partial\n",
       "1299     Normal\n",
       "1300     Normal\n",
       "1301     Normal\n",
       "1302     Normal\n",
       "1303     Normal\n",
       "1304     Normal\n",
       "1305     Normal\n",
       "1306    Partial\n",
       "1307     Normal\n",
       "1308     Normal\n",
       "1309     Normal\n",
       "1310     Normal\n",
       "1311    Partial\n",
       "1312     Normal\n",
       "1313     Normal\n",
       "1314     Normal\n",
       "1315     Normal\n",
       "1316     Normal\n",
       "1317    Partial\n",
       "1318     Normal\n",
       "1319     Normal\n",
       "1320     Normal\n",
       "1321     Normal\n",
       "1322     Normal\n",
       "1323     Normal\n",
       "1324    Partial\n",
       "1325     Normal\n",
       "1326     Normal\n",
       "1327     Normal\n",
       "1328     Normal\n",
       "1329     Normal\n",
       "1330     Normal\n",
       "1331     Normal\n",
       "1332     Normal\n",
       "1333     Normal\n",
       "1334     Normal\n",
       "1335     Normal\n",
       "1336     Normal\n",
       "1337     Normal\n",
       "1338     Normal\n",
       "1339     Normal\n",
       "1340     Normal\n",
       "1341     Normal\n",
       "1342     Normal\n",
       "1343     Normal\n",
       "1344    Partial\n",
       "1345     Normal\n",
       "1346     Normal\n",
       "1347    Partial\n",
       "1348     Normal\n",
       "1349     Normal\n",
       "1350     Normal\n",
       "1351     Normal\n",
       "1352     Normal\n",
       "1353     Normal\n",
       "1354     Normal\n",
       "1355     Normal\n",
       "1356     Normal\n",
       "1357     Normal\n",
       "1358     Normal\n",
       "1359     Normal\n",
       "1360     Normal\n",
       "1361     Normal\n",
       "1362     Normal\n",
       "1363    Partial\n",
       "1364    Abnorml\n",
       "1365     Normal\n",
       "1366    Abnorml\n",
       "1367     Normal\n",
       "1368     Normal\n",
       "1369     Normal\n",
       "1370     Normal\n",
       "1371     Normal\n",
       "1372     Normal\n",
       "1373     Normal\n",
       "1374     Normal\n",
       "1375    Partial\n",
       "1376     Normal\n",
       "1377     Normal\n",
       "1378     Normal\n",
       "1379     Normal\n",
       "1380     Normal\n",
       "1381     Normal\n",
       "1382     Normal\n",
       "1383     Normal\n",
       "1384     Normal\n",
       "1385     Normal\n",
       "1386     Normal\n",
       "1387      Other\n",
       "1388     Normal\n",
       "1389     Normal\n",
       "1390     Normal\n",
       "1391     Normal\n",
       "1392     Normal\n",
       "1393     Normal\n",
       "1394    Partial\n",
       "1395     Normal\n",
       "1396     Normal\n",
       "1397     Normal\n",
       "1398     Normal\n",
       "1399     Normal\n",
       "1400     Normal\n",
       "1401     Normal\n",
       "1402    Partial\n",
       "1403     Normal\n",
       "1404      Other\n",
       "1405     Normal\n",
       "1406     Normal\n",
       "1407     Normal\n",
       "1408     Normal\n",
       "1409     Normal\n",
       "1410     Normal\n",
       "1411     Normal\n",
       "1412     Normal\n",
       "1413    Abnorml\n",
       "1414     Normal\n",
       "1415     Normal\n",
       "1416     Normal\n",
       "1417     Normal\n",
       "1418     Normal\n",
       "1419     Normal\n",
       "1420     Normal\n",
       "1421     Normal\n",
       "1422     Normal\n",
       "1423      Other\n",
       "1424     Normal\n",
       "1425     Normal\n",
       "1426     Normal\n",
       "1427     Normal\n",
       "1428    Abnorml\n",
       "1429     Normal\n",
       "1430     Normal\n",
       "1431     Normal\n",
       "1432     Normal\n",
       "1433     Normal\n",
       "1434     Normal\n",
       "1435    Abnorml\n",
       "1436     Normal\n",
       "1437    Partial\n",
       "1438     Normal\n",
       "1439     Normal\n",
       "1440     Normal\n",
       "1441     Normal\n",
       "1442     Normal\n",
       "1443     Normal\n",
       "1444     Normal\n",
       "1445     Normal\n",
       "1446     Normal\n",
       "1447     Normal\n",
       "1448     Normal\n",
       "1449    Abnorml\n",
       "1450     Normal\n",
       "1451    Partial\n",
       "1452     Normal\n",
       "1453    Abnorml\n",
       "1454     Normal\n",
       "1455     Normal\n",
       "1456     Normal\n",
       "1457     Normal\n",
       "1458     Normal\n",
       "1459     Normal\n",
       "0        Normal\n",
       "1        Normal\n",
       "2        Normal\n",
       "3        Normal\n",
       "4        Normal\n",
       "5        Normal\n",
       "6        Normal\n",
       "7        Normal\n",
       "8        Normal\n",
       "9        Normal\n",
       "10       Normal\n",
       "11       Normal\n",
       "12       Normal\n",
       "13       Normal\n",
       "14       Normal\n",
       "15      Partial\n",
       "16      Partial\n",
       "17       Normal\n",
       "18       Normal\n",
       "19       Normal\n",
       "20       Normal\n",
       "21       Normal\n",
       "22       Normal\n",
       "23       Normal\n",
       "24       Normal\n",
       "25       Normal\n",
       "26       Normal\n",
       "27       Normal\n",
       "28      Partial\n",
       "29       Normal\n",
       "30       Normal\n",
       "31       Normal\n",
       "32      Abnorml\n",
       "33       Normal\n",
       "34       Normal\n",
       "35       Normal\n",
       "36       Normal\n",
       "37       Normal\n",
       "38       Normal\n",
       "39       Normal\n",
       "40       Normal\n",
       "41       Normal\n",
       "42      Partial\n",
       "43       Normal\n",
       "44       Normal\n",
       "45       Normal\n",
       "46       Normal\n",
       "47       Normal\n",
       "48       Normal\n",
       "49       Normal\n",
       "50       Normal\n",
       "51       Normal\n",
       "52        Other\n",
       "53      Abnorml\n",
       "54       Normal\n",
       "55       Normal\n",
       "56       Normal\n",
       "57       Normal\n",
       "58       Normal\n",
       "59       Normal\n",
       "60       Normal\n",
       "61       Normal\n",
       "62       Normal\n",
       "63       Normal\n",
       "64       Normal\n",
       "65      Abnorml\n",
       "66       Normal\n",
       "67       Normal\n",
       "68       Normal\n",
       "69       Normal\n",
       "70      Abnorml\n",
       "71       Normal\n",
       "72       Normal\n",
       "73       Normal\n",
       "74       Normal\n",
       "75       Normal\n",
       "76      Abnorml\n",
       "77      Abnorml\n",
       "78       Normal\n",
       "79      Abnorml\n",
       "80       Normal\n",
       "81       Normal\n",
       "82       Normal\n",
       "83       Normal\n",
       "84      Abnorml\n",
       "85       Normal\n",
       "86       Normal\n",
       "87       Normal\n",
       "88       Normal\n",
       "89       Normal\n",
       "90       Normal\n",
       "91       Normal\n",
       "92       Normal\n",
       "93       Normal\n",
       "94       Normal\n",
       "95       Normal\n",
       "96       Normal\n",
       "97       Normal\n",
       "98      Abnorml\n",
       "99       Normal\n",
       "100      Normal\n",
       "101      Normal\n",
       "102      Normal\n",
       "103      Normal\n",
       "104      Normal\n",
       "105      Normal\n",
       "106      Normal\n",
       "107      Normal\n",
       "108      Normal\n",
       "109      Normal\n",
       "110      Normal\n",
       "111      Normal\n",
       "112     Partial\n",
       "113      Normal\n",
       "114      Normal\n",
       "115      Normal\n",
       "116      Normal\n",
       "117      Normal\n",
       "118      Normal\n",
       "119      Normal\n",
       "120      Normal\n",
       "121      Normal\n",
       "122      Normal\n",
       "123      Normal\n",
       "124      Normal\n",
       "125      Normal\n",
       "126     Abnorml\n",
       "127      Normal\n",
       "128     Abnorml\n",
       "129      Normal\n",
       "130      Normal\n",
       "131      Normal\n",
       "132      Normal\n",
       "133      Normal\n",
       "134      Normal\n",
       "135      Normal\n",
       "136      Normal\n",
       "137      Normal\n",
       "138      Normal\n",
       "139      Normal\n",
       "140      Normal\n",
       "141      Normal\n",
       "142       Other\n",
       "143      Normal\n",
       "144      Normal\n",
       "145      Normal\n",
       "146      Normal\n",
       "147      Normal\n",
       "148     Partial\n",
       "149      Normal\n",
       "150      Normal\n",
       "151      Normal\n",
       "152      Normal\n",
       "153      Normal\n",
       "154      Normal\n",
       "155      Normal\n",
       "156      Normal\n",
       "157      Normal\n",
       "158      Normal\n",
       "159      Normal\n",
       "160      Normal\n",
       "161      Normal\n",
       "162      Normal\n",
       "163      Normal\n",
       "164      Normal\n",
       "165      Normal\n",
       "166      Normal\n",
       "167      Normal\n",
       "168      Normal\n",
       "169      Normal\n",
       "170      Normal\n",
       "171      Normal\n",
       "172      Normal\n",
       "173      Normal\n",
       "174      Normal\n",
       "175      Normal\n",
       "176      Normal\n",
       "177     Abnorml\n",
       "178      Normal\n",
       "179      Normal\n",
       "180      Normal\n",
       "181      Normal\n",
       "182      Normal\n",
       "183      Normal\n",
       "184      Normal\n",
       "185      Normal\n",
       "186      Normal\n",
       "187      Normal\n",
       "188      Normal\n",
       "189     Abnorml\n",
       "190      Normal\n",
       "191      Normal\n",
       "192      Normal\n",
       "193      Normal\n",
       "194      Normal\n",
       "195      Normal\n",
       "196      Normal\n",
       "197      Normal\n",
       "198      Normal\n",
       "199      Normal\n",
       "200      Normal\n",
       "201     Partial\n",
       "202      Normal\n",
       "203      Normal\n",
       "204      Normal\n",
       "205      Normal\n",
       "206       Other\n",
       "207      Normal\n",
       "208      Normal\n",
       "209      Normal\n",
       "210      Normal\n",
       "211      Normal\n",
       "212      Normal\n",
       "213      Normal\n",
       "214      Normal\n",
       "215      Normal\n",
       "216      Normal\n",
       "217     Abnorml\n",
       "218      Normal\n",
       "219     Partial\n",
       "220      Normal\n",
       "221      Normal\n",
       "222      Normal\n",
       "223      Normal\n",
       "224      Normal\n",
       "225      Normal\n",
       "226      Normal\n",
       "227      Normal\n",
       "228      Normal\n",
       "229      Normal\n",
       "230      Normal\n",
       "231      Normal\n",
       "232      Normal\n",
       "233      Normal\n",
       "234      Normal\n",
       "235      Normal\n",
       "236      Normal\n",
       "237      Normal\n",
       "238      Normal\n",
       "239      Normal\n",
       "240      Normal\n",
       "241      Normal\n",
       "242      Normal\n",
       "243      Normal\n",
       "244      Normal\n",
       "245      Normal\n",
       "246     Partial\n",
       "247      Normal\n",
       "248      Normal\n",
       "249      Normal\n",
       "250      Normal\n",
       "251     Partial\n",
       "252      Normal\n",
       "253      Normal\n",
       "254      Normal\n",
       "255      Normal\n",
       "256      Normal\n",
       "257      Normal\n",
       "258      Normal\n",
       "259      Normal\n",
       "260      Normal\n",
       "261      Normal\n",
       "262      Normal\n",
       "263     Partial\n",
       "264      Normal\n",
       "265      Normal\n",
       "266      Normal\n",
       "267      Normal\n",
       "268      Normal\n",
       "269      Normal\n",
       "270      Normal\n",
       "271      Normal\n",
       "272      Normal\n",
       "273       Other\n",
       "274      Normal\n",
       "275      Normal\n",
       "276      Normal\n",
       "277      Normal\n",
       "278      Normal\n",
       "279     Partial\n",
       "280      Normal\n",
       "281      Normal\n",
       "282      Normal\n",
       "283      Normal\n",
       "284      Normal\n",
       "285     Abnorml\n",
       "286      Normal\n",
       "287      Normal\n",
       "288      Normal\n",
       "289     Abnorml\n",
       "290      Normal\n",
       "291      Normal\n",
       "292      Normal\n",
       "293     Abnorml\n",
       "294      Normal\n",
       "295      Normal\n",
       "296      Normal\n",
       "297      Normal\n",
       "298      Normal\n",
       "299      Normal\n",
       "300     Abnorml\n",
       "301      Normal\n",
       "302      Normal\n",
       "303      Normal\n",
       "304      Normal\n",
       "305      Normal\n",
       "306      Normal\n",
       "307      Normal\n",
       "308      Normal\n",
       "309      Normal\n",
       "310     Abnorml\n",
       "311      Normal\n",
       "312       Other\n",
       "313      Normal\n",
       "314      Normal\n",
       "315      Normal\n",
       "316      Normal\n",
       "317      Normal\n",
       "318      Normal\n",
       "319      Normal\n",
       "320      Normal\n",
       "321      Normal\n",
       "322      Normal\n",
       "323      Normal\n",
       "324      Normal\n",
       "325      Normal\n",
       "326      Normal\n",
       "327      Normal\n",
       "328      Normal\n",
       "329      Normal\n",
       "330      Normal\n",
       "331      Normal\n",
       "332      Normal\n",
       "333      Normal\n",
       "334      Normal\n",
       "335      Normal\n",
       "336     Abnorml\n",
       "337      Normal\n",
       "338      Normal\n",
       "339      Normal\n",
       "340      Normal\n",
       "341     Abnorml\n",
       "342      Normal\n",
       "343      Normal\n",
       "344      Normal\n",
       "345      Normal\n",
       "346      Normal\n",
       "347      Normal\n",
       "348      Normal\n",
       "349      Normal\n",
       "350      Normal\n",
       "351      Normal\n",
       "352      Normal\n",
       "353      Normal\n",
       "354      Normal\n",
       "355      Normal\n",
       "356      Normal\n",
       "357      Normal\n",
       "358      Normal\n",
       "359      Normal\n",
       "360       Other\n",
       "361      Normal\n",
       "362     Abnorml\n",
       "363      Normal\n",
       "364      Normal\n",
       "365      Normal\n",
       "366     Abnorml\n",
       "367      Normal\n",
       "368      Normal\n",
       "369      Normal\n",
       "370      Normal\n",
       "371     Abnorml\n",
       "372      Normal\n",
       "373      Normal\n",
       "374      Normal\n",
       "375      Normal\n",
       "376     Abnorml\n",
       "377      Normal\n",
       "378      Normal\n",
       "379       Other\n",
       "380      Normal\n",
       "381      Normal\n",
       "382     Abnorml\n",
       "383      Normal\n",
       "384      Normal\n",
       "385      Normal\n",
       "386      Normal\n",
       "387      Normal\n",
       "388      Normal\n",
       "389      Normal\n",
       "390      Normal\n",
       "391      Normal\n",
       "392      Normal\n",
       "393      Normal\n",
       "394      Normal\n",
       "395      Normal\n",
       "396      Normal\n",
       "397       Other\n",
       "398       Other\n",
       "399       Other\n",
       "400       Other\n",
       "401      Normal\n",
       "402      Normal\n",
       "403      Normal\n",
       "404     Partial\n",
       "405      Normal\n",
       "406      Normal\n",
       "407      Normal\n",
       "408      Normal\n",
       "409      Normal\n",
       "410      Normal\n",
       "411      Normal\n",
       "412      Normal\n",
       "413      Normal\n",
       "414      Normal\n",
       "415      Normal\n",
       "416      Normal\n",
       "417       Other\n",
       "418      Normal\n",
       "419      Normal\n",
       "420      Normal\n",
       "421      Normal\n",
       "422      Normal\n",
       "423      Normal\n",
       "424      Normal\n",
       "425      Normal\n",
       "426      Normal\n",
       "427      Normal\n",
       "428      Normal\n",
       "429      Normal\n",
       "430      Normal\n",
       "431      Normal\n",
       "432      Normal\n",
       "433      Normal\n",
       "434      Normal\n",
       "435      Normal\n",
       "436     Abnorml\n",
       "437      Normal\n",
       "438      Normal\n",
       "439      Normal\n",
       "440      Normal\n",
       "441      Normal\n",
       "442      Normal\n",
       "443       Other\n",
       "444      Normal\n",
       "445      Normal\n",
       "446      Normal\n",
       "447      Normal\n",
       "448      Normal\n",
       "449      Normal\n",
       "450      Normal\n",
       "451      Normal\n",
       "452      Normal\n",
       "453      Normal\n",
       "454     Partial\n",
       "455      Normal\n",
       "456      Normal\n",
       "457      Normal\n",
       "458      Normal\n",
       "459     Abnorml\n",
       "460      Normal\n",
       "461      Normal\n",
       "462      Normal\n",
       "463      Normal\n",
       "464     Abnorml\n",
       "465      Normal\n",
       "466      Normal\n",
       "467      Normal\n",
       "468      Normal\n",
       "469      Normal\n",
       "470      Normal\n",
       "471      Normal\n",
       "472      Normal\n",
       "473      Normal\n",
       "474      Normal\n",
       "475      Normal\n",
       "476      Normal\n",
       "477      Normal\n",
       "478      Normal\n",
       "479      Normal\n",
       "480       Other\n",
       "481      Normal\n",
       "482      Normal\n",
       "483      Normal\n",
       "484      Normal\n",
       "485      Normal\n",
       "486      Normal\n",
       "487       Other\n",
       "488      Normal\n",
       "489      Normal\n",
       "490      Normal\n",
       "491      Normal\n",
       "492      Normal\n",
       "493      Normal\n",
       "494      Normal\n",
       "495      Normal\n",
       "496      Normal\n",
       "497      Normal\n",
       "498      Normal\n",
       "499      Normal\n",
       "500      Normal\n",
       "501      Normal\n",
       "502      Normal\n",
       "503      Normal\n",
       "504      Normal\n",
       "505      Normal\n",
       "506     Partial\n",
       "507      Normal\n",
       "508      Normal\n",
       "509     Abnorml\n",
       "510      Normal\n",
       "511      Normal\n",
       "512      Normal\n",
       "513      Normal\n",
       "514      Normal\n",
       "515      Normal\n",
       "516      Normal\n",
       "517      Normal\n",
       "518     Partial\n",
       "519      Normal\n",
       "520     Partial\n",
       "521      Normal\n",
       "522      Normal\n",
       "523      Normal\n",
       "524      Normal\n",
       "525      Normal\n",
       "526     Partial\n",
       "527      Normal\n",
       "528      Normal\n",
       "529      Normal\n",
       "530     Partial\n",
       "531      Normal\n",
       "532      Normal\n",
       "533      Normal\n",
       "534      Normal\n",
       "535      Normal\n",
       "536      Normal\n",
       "537      Normal\n",
       "538      Normal\n",
       "539      Normal\n",
       "540      Normal\n",
       "541      Normal\n",
       "542      Normal\n",
       "543     Partial\n",
       "544      Normal\n",
       "545     Partial\n",
       "546      Normal\n",
       "547     Partial\n",
       "548      Normal\n",
       "549      Normal\n",
       "550      Normal\n",
       "551      Normal\n",
       "552      Normal\n",
       "553      Normal\n",
       "554      Normal\n",
       "555      Normal\n",
       "556      Normal\n",
       "557      Normal\n",
       "558      Normal\n",
       "559      Normal\n",
       "560     Abnorml\n",
       "561      Normal\n",
       "562      Normal\n",
       "563      Normal\n",
       "564      Normal\n",
       "565      Normal\n",
       "566      Normal\n",
       "567     Abnorml\n",
       "568      Normal\n",
       "569      Normal\n",
       "570      Normal\n",
       "571      Normal\n",
       "572      Normal\n",
       "573      Normal\n",
       "574      Normal\n",
       "575      Normal\n",
       "576      Normal\n",
       "577      Normal\n",
       "578      Normal\n",
       "579       Other\n",
       "580      Normal\n",
       "581      Normal\n",
       "582      Normal\n",
       "583       Other\n",
       "584      Normal\n",
       "585      Normal\n",
       "586      Normal\n",
       "587      Normal\n",
       "588      Normal\n",
       "589      Normal\n",
       "590      Normal\n",
       "591     Abnorml\n",
       "592      Normal\n",
       "593      Normal\n",
       "594      Normal\n",
       "595      Normal\n",
       "596      Normal\n",
       "597      Normal\n",
       "598      Normal\n",
       "599      Normal\n",
       "600      Normal\n",
       "601      Normal\n",
       "602      Normal\n",
       "603      Normal\n",
       "604      Normal\n",
       "605      Normal\n",
       "606      Normal\n",
       "607      Normal\n",
       "608      Normal\n",
       "609      Normal\n",
       "610      Normal\n",
       "611      Normal\n",
       "612      Normal\n",
       "613      Normal\n",
       "614      Normal\n",
       "615     Abnorml\n",
       "616      Normal\n",
       "617      Normal\n",
       "618      Normal\n",
       "619      Normal\n",
       "620      Normal\n",
       "621     Abnorml\n",
       "622      Normal\n",
       "623      Normal\n",
       "624      Normal\n",
       "625     Abnorml\n",
       "626      Normal\n",
       "627      Normal\n",
       "628      Normal\n",
       "629      Normal\n",
       "630      Normal\n",
       "631      Normal\n",
       "632      Normal\n",
       "633      Normal\n",
       "634      Normal\n",
       "635      Normal\n",
       "636      Normal\n",
       "637      Normal\n",
       "638     Abnorml\n",
       "639     Abnorml\n",
       "640      Normal\n",
       "641      Normal\n",
       "642      Normal\n",
       "643      Normal\n",
       "644      Normal\n",
       "645      Normal\n",
       "646      Normal\n",
       "647      Normal\n",
       "648      Normal\n",
       "649      Normal\n",
       "650     Abnorml\n",
       "651      Normal\n",
       "652      Normal\n",
       "653      Normal\n",
       "654      Normal\n",
       "655      Normal\n",
       "656      Normal\n",
       "657      Normal\n",
       "658      Normal\n",
       "659      Normal\n",
       "660     Abnorml\n",
       "661      Normal\n",
       "662      Normal\n",
       "663      Normal\n",
       "664      Normal\n",
       "665      Normal\n",
       "666      Normal\n",
       "667      Normal\n",
       "668      Normal\n",
       "669     Abnorml\n",
       "670      Normal\n",
       "671      Normal\n",
       "672      Normal\n",
       "673       Other\n",
       "674       Other\n",
       "675      Normal\n",
       "676     Abnorml\n",
       "677     Abnorml\n",
       "678      Normal\n",
       "679      Normal\n",
       "680      Normal\n",
       "681      Normal\n",
       "682      Normal\n",
       "683       Other\n",
       "684      Normal\n",
       "685      Normal\n",
       "686     Abnorml\n",
       "687      Normal\n",
       "688      Normal\n",
       "689      Normal\n",
       "690      Normal\n",
       "691      Normal\n",
       "692      Normal\n",
       "693      Normal\n",
       "694      Normal\n",
       "695      Normal\n",
       "696      Normal\n",
       "697      Normal\n",
       "698      Normal\n",
       "699     Partial\n",
       "700      Normal\n",
       "701     Abnorml\n",
       "702     Partial\n",
       "703      Normal\n",
       "704      Normal\n",
       "705      Normal\n",
       "706      Normal\n",
       "707      Normal\n",
       "708      Normal\n",
       "709      Normal\n",
       "710      Normal\n",
       "711     Abnorml\n",
       "712      Normal\n",
       "713      Normal\n",
       "714      Normal\n",
       "715      Normal\n",
       "716      Normal\n",
       "717      Normal\n",
       "718      Normal\n",
       "719     Abnorml\n",
       "720      Normal\n",
       "721      Normal\n",
       "722      Normal\n",
       "723     Abnorml\n",
       "724       Other\n",
       "725      Normal\n",
       "726      Normal\n",
       "727      Normal\n",
       "728      Normal\n",
       "729       Other\n",
       "730      Normal\n",
       "731      Normal\n",
       "732       Other\n",
       "733      Normal\n",
       "734      Normal\n",
       "735     Abnorml\n",
       "736      Normal\n",
       "737      Normal\n",
       "738     Abnorml\n",
       "739      Normal\n",
       "740      Normal\n",
       "741      Normal\n",
       "742      Normal\n",
       "743      Normal\n",
       "744      Normal\n",
       "745      Normal\n",
       "746       Other\n",
       "747      Normal\n",
       "748      Normal\n",
       "749      Normal\n",
       "750      Normal\n",
       "751      Normal\n",
       "752      Normal\n",
       "753      Normal\n",
       "754      Normal\n",
       "755      Normal\n",
       "756     Abnorml\n",
       "757      Normal\n",
       "758      Normal\n",
       "759      Normal\n",
       "760     Partial\n",
       "761      Normal\n",
       "762      Normal\n",
       "763      Normal\n",
       "764     Abnorml\n",
       "765      Normal\n",
       "766      Normal\n",
       "767      Normal\n",
       "768     Partial\n",
       "769      Normal\n",
       "770     Partial\n",
       "771      Normal\n",
       "772      Normal\n",
       "773      Normal\n",
       "774      Normal\n",
       "775      Normal\n",
       "776      Normal\n",
       "777       Other\n",
       "778     Abnorml\n",
       "779      Normal\n",
       "780      Normal\n",
       "781      Normal\n",
       "782      Normal\n",
       "783      Normal\n",
       "784      Normal\n",
       "785      Normal\n",
       "786      Normal\n",
       "787      Normal\n",
       "788      Normal\n",
       "789      Normal\n",
       "790      Normal\n",
       "791      Normal\n",
       "792      Normal\n",
       "793      Normal\n",
       "794     Abnorml\n",
       "795      Normal\n",
       "796      Normal\n",
       "797      Normal\n",
       "798      Normal\n",
       "799       Other\n",
       "800      Normal\n",
       "801      Normal\n",
       "802      Normal\n",
       "803     Partial\n",
       "804      Normal\n",
       "805      Normal\n",
       "806      Normal\n",
       "807     Partial\n",
       "808     Abnorml\n",
       "809      Normal\n",
       "810      Normal\n",
       "811      Normal\n",
       "812      Normal\n",
       "813      Normal\n",
       "814      Normal\n",
       "815      Normal\n",
       "816      Normal\n",
       "817      Normal\n",
       "818      Normal\n",
       "819      Normal\n",
       "820      Normal\n",
       "821      Normal\n",
       "822      Normal\n",
       "823      Normal\n",
       "824      Normal\n",
       "825      Normal\n",
       "826     Partial\n",
       "827     Partial\n",
       "828     Partial\n",
       "829     Partial\n",
       "830     Partial\n",
       "831      Normal\n",
       "832     Partial\n",
       "833      Normal\n",
       "834     Partial\n",
       "835     Partial\n",
       "836     Partial\n",
       "837      Normal\n",
       "838      Normal\n",
       "839      Normal\n",
       "840     Partial\n",
       "841      Normal\n",
       "842      Normal\n",
       "843     Partial\n",
       "844     Partial\n",
       "845      Normal\n",
       "846      Normal\n",
       "847      Normal\n",
       "848      Normal\n",
       "849     Partial\n",
       "850      Normal\n",
       "851     Partial\n",
       "852      Normal\n",
       "853     Partial\n",
       "854     Partial\n",
       "855     Partial\n",
       "856      Normal\n",
       "857     Partial\n",
       "858     Partial\n",
       "859     Partial\n",
       "860      Normal\n",
       "861     Partial\n",
       "862      Normal\n",
       "863       Other\n",
       "864     Partial\n",
       "865      Normal\n",
       "866      Normal\n",
       "867      Normal\n",
       "868      Normal\n",
       "869      Normal\n",
       "870      Normal\n",
       "871      Normal\n",
       "872      Normal\n",
       "873      Normal\n",
       "874      Normal\n",
       "875      Normal\n",
       "876     Partial\n",
       "877     Partial\n",
       "878       Other\n",
       "879     Partial\n",
       "880     Partial\n",
       "881      Normal\n",
       "882      Normal\n",
       "883       Other\n",
       "884      Normal\n",
       "885     Partial\n",
       "886     Partial\n",
       "887     Partial\n",
       "888     Partial\n",
       "889     Partial\n",
       "890     Partial\n",
       "891      Normal\n",
       "892      Normal\n",
       "893     Partial\n",
       "894      Normal\n",
       "895      Normal\n",
       "896      Normal\n",
       "897      Normal\n",
       "898      Normal\n",
       "899      Normal\n",
       "900      Normal\n",
       "901      Normal\n",
       "902      Normal\n",
       "903     Abnorml\n",
       "904      Normal\n",
       "905     Partial\n",
       "906     Partial\n",
       "907     Partial\n",
       "908     Partial\n",
       "909      Normal\n",
       "910      Normal\n",
       "911      Normal\n",
       "912      Normal\n",
       "913      Normal\n",
       "914      Normal\n",
       "915      Normal\n",
       "916      Normal\n",
       "917      Normal\n",
       "918      Normal\n",
       "919      Normal\n",
       "920      Normal\n",
       "921      Normal\n",
       "922      Normal\n",
       "923      Normal\n",
       "924      Normal\n",
       "925      Normal\n",
       "926      Normal\n",
       "927      Normal\n",
       "928      Normal\n",
       "929      Normal\n",
       "930      Normal\n",
       "931      Normal\n",
       "932      Normal\n",
       "933      Normal\n",
       "934      Normal\n",
       "935      Normal\n",
       "936      Normal\n",
       "937      Normal\n",
       "938      Normal\n",
       "939      Normal\n",
       "940      Normal\n",
       "941      Normal\n",
       "942      Normal\n",
       "943      Normal\n",
       "944      Normal\n",
       "945      Normal\n",
       "946      Normal\n",
       "947      Normal\n",
       "948      Normal\n",
       "949      Normal\n",
       "950      Normal\n",
       "951      Normal\n",
       "952      Normal\n",
       "953      Normal\n",
       "954      Normal\n",
       "955      Normal\n",
       "956      Normal\n",
       "957      Normal\n",
       "958      Normal\n",
       "959      Normal\n",
       "960      Normal\n",
       "961      Normal\n",
       "962      Normal\n",
       "963      Normal\n",
       "964       Other\n",
       "965     Abnorml\n",
       "966      Normal\n",
       "967      Normal\n",
       "968     Abnorml\n",
       "969      Normal\n",
       "970      Normal\n",
       "971      Normal\n",
       "972      Normal\n",
       "973       Other\n",
       "974      Normal\n",
       "975      Normal\n",
       "976      Normal\n",
       "977      Normal\n",
       "978      Normal\n",
       "979      Normal\n",
       "980      Normal\n",
       "981      Normal\n",
       "982      Normal\n",
       "983      Normal\n",
       "984      Normal\n",
       "985      Normal\n",
       "986      Normal\n",
       "987     Abnorml\n",
       "988      Normal\n",
       "989      Normal\n",
       "990     Partial\n",
       "991      Normal\n",
       "992      Normal\n",
       "993      Normal\n",
       "994      Normal\n",
       "995      Normal\n",
       "996      Normal\n",
       "997      Normal\n",
       "998      Normal\n",
       "999      Normal\n",
       "1000     Normal\n",
       "1001     Normal\n",
       "1002     Normal\n",
       "1003     Normal\n",
       "1004     Normal\n",
       "1005      Other\n",
       "1006     Normal\n",
       "1007      Other\n",
       "1008      Other\n",
       "1009     Normal\n",
       "1010     Normal\n",
       "1011     Normal\n",
       "1012    Abnorml\n",
       "1013    Abnorml\n",
       "1014     Normal\n",
       "1015     Normal\n",
       "1016     Normal\n",
       "1017     Normal\n",
       "1018     Normal\n",
       "1019     Normal\n",
       "1020     Normal\n",
       "1021     Normal\n",
       "1022     Normal\n",
       "1023     Normal\n",
       "1024     Normal\n",
       "1025     Normal\n",
       "1026     Normal\n",
       "1027     Normal\n",
       "1028     Normal\n",
       "1029     Normal\n",
       "1030     Normal\n",
       "1031     Normal\n",
       "1032     Normal\n",
       "1033     Normal\n",
       "1034     Normal\n",
       "1035     Normal\n",
       "1036     Normal\n",
       "1037     Normal\n",
       "1038     Normal\n",
       "1039     Normal\n",
       "1040     Normal\n",
       "1041     Normal\n",
       "1042     Normal\n",
       "1043     Normal\n",
       "1044     Normal\n",
       "1045    Partial\n",
       "1046    Partial\n",
       "1047    Partial\n",
       "1048     Normal\n",
       "1049     Normal\n",
       "1050     Normal\n",
       "1051     Normal\n",
       "1052     Normal\n",
       "1053     Normal\n",
       "1054     Normal\n",
       "1055     Normal\n",
       "1056     Normal\n",
       "1057     Normal\n",
       "1058     Normal\n",
       "1059     Normal\n",
       "1060     Normal\n",
       "1061     Normal\n",
       "1062      Other\n",
       "1063     Normal\n",
       "1064     Normal\n",
       "1065     Normal\n",
       "1066     Normal\n",
       "1067     Normal\n",
       "1068     Normal\n",
       "1069     Normal\n",
       "1070     Normal\n",
       "1071     Normal\n",
       "1072     Normal\n",
       "1073     Normal\n",
       "1074     Normal\n",
       "1075     Normal\n",
       "1076     Normal\n",
       "1077    Partial\n",
       "1078     Normal\n",
       "1079    Partial\n",
       "1080     Normal\n",
       "1081     Normal\n",
       "1082    Abnorml\n",
       "1083     Normal\n",
       "1084     Normal\n",
       "1085     Normal\n",
       "1086     Normal\n",
       "1087     Normal\n",
       "1088     Normal\n",
       "1089    Partial\n",
       "1090     Normal\n",
       "1091     Normal\n",
       "1092     Normal\n",
       "1093    Abnorml\n",
       "1094     Normal\n",
       "1095     Normal\n",
       "1096      Other\n",
       "1097      Other\n",
       "1098     Normal\n",
       "1099     Normal\n",
       "1100     Normal\n",
       "1101     Normal\n",
       "1102     Normal\n",
       "1103     Normal\n",
       "1104     Normal\n",
       "1105     Normal\n",
       "1106     Normal\n",
       "1107     Normal\n",
       "1108     Normal\n",
       "1109     Normal\n",
       "1110     Normal\n",
       "1111     Normal\n",
       "1112     Normal\n",
       "1113     Normal\n",
       "1114     Normal\n",
       "1115     Normal\n",
       "1116      Other\n",
       "1117     Normal\n",
       "1118     Normal\n",
       "1119     Normal\n",
       "1120    Abnorml\n",
       "1121     Normal\n",
       "1122    Partial\n",
       "1123     Normal\n",
       "1124     Normal\n",
       "1125     Normal\n",
       "1126     Normal\n",
       "1127     Normal\n",
       "1128     Normal\n",
       "1129     Normal\n",
       "1130     Normal\n",
       "1131    Partial\n",
       "1132    Partial\n",
       "1133     Normal\n",
       "1134     Normal\n",
       "1135     Normal\n",
       "1136     Normal\n",
       "1137     Normal\n",
       "1138    Partial\n",
       "1139     Normal\n",
       "1140     Normal\n",
       "1141     Normal\n",
       "1142     Normal\n",
       "1143     Normal\n",
       "1144     Normal\n",
       "1145     Normal\n",
       "1146     Normal\n",
       "1147     Normal\n",
       "1148     Normal\n",
       "1149     Normal\n",
       "1150    Abnorml\n",
       "1151     Normal\n",
       "1152     Normal\n",
       "1153     Normal\n",
       "1154     Normal\n",
       "1155     Normal\n",
       "1156     Normal\n",
       "1157    Abnorml\n",
       "1158     Normal\n",
       "1159     Normal\n",
       "1160     Normal\n",
       "1161     Normal\n",
       "1162     Normal\n",
       "1163    Partial\n",
       "1164     Normal\n",
       "1165     Normal\n",
       "1166     Normal\n",
       "1167    Partial\n",
       "1168    Partial\n",
       "1169    Partial\n",
       "1170    Partial\n",
       "1171    Partial\n",
       "1172     Normal\n",
       "1173     Normal\n",
       "1174     Normal\n",
       "1175     Normal\n",
       "1176     Normal\n",
       "1177    Partial\n",
       "1178     Normal\n",
       "1179     Normal\n",
       "1180     Normal\n",
       "1181     Normal\n",
       "1182     Normal\n",
       "1183     Normal\n",
       "1184     Normal\n",
       "1185     Normal\n",
       "1186     Normal\n",
       "1187     Normal\n",
       "1188     Normal\n",
       "1189     Normal\n",
       "1190     Normal\n",
       "1191    Partial\n",
       "1192     Normal\n",
       "1193    Partial\n",
       "1194     Normal\n",
       "1195    Partial\n",
       "1196    Partial\n",
       "1197    Partial\n",
       "1198    Partial\n",
       "1199    Partial\n",
       "1200    Partial\n",
       "1201     Normal\n",
       "1202     Normal\n",
       "1203     Normal\n",
       "1204    Partial\n",
       "1205    Partial\n",
       "1206    Partial\n",
       "1207    Partial\n",
       "1208    Partial\n",
       "1209    Partial\n",
       "1210    Partial\n",
       "1211    Partial\n",
       "1212     Normal\n",
       "1213     Normal\n",
       "1214    Partial\n",
       "1215     Normal\n",
       "1216     Normal\n",
       "1217    Partial\n",
       "1218     Normal\n",
       "1219     Normal\n",
       "1220     Normal\n",
       "1221     Normal\n",
       "1222     Normal\n",
       "1223     Normal\n",
       "1224     Normal\n",
       "1225    Partial\n",
       "1226    Partial\n",
       "1227    Partial\n",
       "1228    Partial\n",
       "1229    Partial\n",
       "1230     Normal\n",
       "1231     Normal\n",
       "1232    Partial\n",
       "1233    Partial\n",
       "1234     Normal\n",
       "1235     Normal\n",
       "1236     Normal\n",
       "1237      Other\n",
       "1238     Normal\n",
       "1239     Normal\n",
       "1240     Normal\n",
       "1241     Normal\n",
       "1242     Normal\n",
       "1243     Normal\n",
       "1244     Normal\n",
       "1245     Normal\n",
       "1246     Normal\n",
       "1247     Normal\n",
       "1248     Normal\n",
       "1249     Normal\n",
       "1250     Normal\n",
       "1251     Normal\n",
       "1252     Normal\n",
       "1253     Normal\n",
       "1254     Normal\n",
       "1255     Normal\n",
       "1256     Normal\n",
       "1257     Normal\n",
       "1258     Normal\n",
       "1259     Normal\n",
       "1260     Normal\n",
       "1261     Normal\n",
       "1262    Abnorml\n",
       "1263     Normal\n",
       "1264     Normal\n",
       "1265     Normal\n",
       "1266    Abnorml\n",
       "1267     Normal\n",
       "1268     Normal\n",
       "1269     Normal\n",
       "1270     Normal\n",
       "1271     Normal\n",
       "1272     Normal\n",
       "1273    Partial\n",
       "1274     Normal\n",
       "1275     Normal\n",
       "1276     Normal\n",
       "1277     Normal\n",
       "1278     Normal\n",
       "1279     Normal\n",
       "1280     Normal\n",
       "1281     Normal\n",
       "1282     Normal\n",
       "1283     Normal\n",
       "1284    Abnorml\n",
       "1285     Normal\n",
       "1286     Normal\n",
       "1287     Normal\n",
       "1288     Normal\n",
       "1289     Normal\n",
       "1290     Normal\n",
       "1291    Abnorml\n",
       "1292     Normal\n",
       "1293     Normal\n",
       "1294     Normal\n",
       "1295     Normal\n",
       "1296     Normal\n",
       "1297     Normal\n",
       "1298     Normal\n",
       "1299    Abnorml\n",
       "1300     Normal\n",
       "1301     Normal\n",
       "1302     Normal\n",
       "1303     Normal\n",
       "1304     Normal\n",
       "1305     Normal\n",
       "1306     Normal\n",
       "1307     Normal\n",
       "1308     Normal\n",
       "1309     Normal\n",
       "1310     Normal\n",
       "1311     Normal\n",
       "1312     Normal\n",
       "1313     Normal\n",
       "1314     Normal\n",
       "1315     Normal\n",
       "1316     Normal\n",
       "1317     Normal\n",
       "1318     Normal\n",
       "1319    Abnorml\n",
       "1320     Normal\n",
       "1321     Normal\n",
       "1322     Normal\n",
       "1323     Normal\n",
       "1324     Normal\n",
       "1325     Normal\n",
       "1326     Normal\n",
       "1327     Normal\n",
       "1328     Normal\n",
       "1329     Normal\n",
       "1330     Normal\n",
       "1331     Normal\n",
       "1332     Normal\n",
       "1333    Abnorml\n",
       "1334     Normal\n",
       "1335     Normal\n",
       "1336     Normal\n",
       "1337    Abnorml\n",
       "1338     Normal\n",
       "1339    Abnorml\n",
       "1340      Other\n",
       "1341     Normal\n",
       "1342     Normal\n",
       "1343     Normal\n",
       "1344     Normal\n",
       "1345     Normal\n",
       "1346     Normal\n",
       "1347     Normal\n",
       "1348     Normal\n",
       "1349    Abnorml\n",
       "1350     Normal\n",
       "1351     Normal\n",
       "1352     Normal\n",
       "1353     Normal\n",
       "1354     Normal\n",
       "1355     Normal\n",
       "1356     Normal\n",
       "1357     Normal\n",
       "1358     Normal\n",
       "1359     Normal\n",
       "1360      Other\n",
       "1361     Normal\n",
       "1362     Normal\n",
       "1363     Normal\n",
       "1364     Normal\n",
       "1365     Normal\n",
       "1366     Normal\n",
       "1367    Abnorml\n",
       "1368     Normal\n",
       "1369    Partial\n",
       "1370    Abnorml\n",
       "1371    Partial\n",
       "1372    Partial\n",
       "1373    Partial\n",
       "1374     Normal\n",
       "1375     Normal\n",
       "1376    Abnorml\n",
       "1377     Normal\n",
       "1378     Normal\n",
       "1379     Normal\n",
       "1380     Normal\n",
       "1381     Normal\n",
       "1382     Normal\n",
       "1383     Normal\n",
       "1384     Normal\n",
       "1385     Normal\n",
       "1386     Normal\n",
       "1387     Normal\n",
       "1388     Normal\n",
       "1389     Normal\n",
       "1390     Normal\n",
       "1391     Normal\n",
       "1392     Normal\n",
       "1393     Normal\n",
       "1394     Normal\n",
       "1395    Partial\n",
       "1396     Normal\n",
       "1397    Partial\n",
       "1398     Normal\n",
       "1399      Other\n",
       "1400    Abnorml\n",
       "1401     Normal\n",
       "1402     Normal\n",
       "1403     Normal\n",
       "1404    Partial\n",
       "1405     Normal\n",
       "1406     Normal\n",
       "1407      Other\n",
       "1408      Other\n",
       "1409    Abnorml\n",
       "1410    Abnorml\n",
       "1411     Normal\n",
       "1412     Normal\n",
       "1413     Normal\n",
       "1414    Abnorml\n",
       "1415     Normal\n",
       "1416     Normal\n",
       "1417    Abnorml\n",
       "1418     Normal\n",
       "1419     Normal\n",
       "1420     Normal\n",
       "1421     Normal\n",
       "1422     Normal\n",
       "1423     Normal\n",
       "1424     Normal\n",
       "1425     Normal\n",
       "1426      Other\n",
       "1427     Normal\n",
       "1428     Normal\n",
       "1429     Normal\n",
       "1430     Normal\n",
       "1431    Abnorml\n",
       "1432    Abnorml\n",
       "1433     Normal\n",
       "1434    Partial\n",
       "1435     Normal\n",
       "1436     Normal\n",
       "1437     Normal\n",
       "1438     Normal\n",
       "1439     Normal\n",
       "1440      Other\n",
       "1441     Normal\n",
       "1442    Partial\n",
       "1443    Partial\n",
       "1444     Normal\n",
       "1445     Normal\n",
       "1446     Normal\n",
       "1447     Normal\n",
       "1448     Normal\n",
       "1449     Normal\n",
       "1450     Normal\n",
       "1451     Normal\n",
       "1452    Abnorml\n",
       "1453     Normal\n",
       "1454     Normal\n",
       "1455    Abnorml\n",
       "1456    Abnorml\n",
       "1457     Normal\n",
       "1458     Normal\n",
       "Name: SaleCondition, dtype: object"
      ]
     },
     "execution_count": 1065,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_df['SaleCondition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число NaN: 0\n",
      "Число уникальный значений: 4\n",
      "SaleCondition\n",
      "Normal     2402\n",
      "Partial     245\n",
      "Abnorml     190\n",
      "Other        82\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_analytics('SaleCondition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [],
   "source": [
    "# перекодирование на 1 и 0\n",
    "\n",
    "# Перекодирование колонки 'Fireplaces' на 1 или 0\n",
    "subm_df['Fireplaces'] = subm_df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "subm_df['SaleCondition'] = recode_category('SaleCondition', 0.05, subm_df)\n",
    "\n",
    "# label coding\n",
    "\n",
    "# # Перекодирование колонки 'HeatingQC'\n",
    "# HeatingQC_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n",
    "# subm_df['HeatingQC'] = subm_df['HeatingQC'].map(HeatingQC_mapping)\n",
    "\n",
    "# Перекодирование колонки 'SaleCondition'\n",
    "SaleCondition_mapping = {'Normal': 1, 'Partial': 2, 'Abnorml': 3, 'Other': 4}\n",
    "subm_df['SaleCondition'] = subm_df['SaleCondition'].map(SaleCondition_mapping)\n",
    "\n",
    "# Перекодирование колонки 'FireplaceQu'\n",
    "FireplaceQu_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n",
    "subm_df['FireplaceQu'] = subm_df['FireplaceQu'].map(FireplaceQu_mapping)\n",
    "subm_df['FireplaceQu'] = subm_df['FireplaceQu'].fillna(0)\n",
    "\n",
    "# subm_df['FireplaceQu'] = subm_df['FireplaceQu'].apply(lambda x: 1 if x in ['Gd', 'Ex'] else 0)\n",
    "\n",
    "# Перекодирование колонки 'KitchenQual'\n",
    "kitchenqual_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n",
    "subm_df['KitchenQual'] = subm_df['KitchenQual'].map(kitchenqual_mapping)\n",
    "\n",
    "# Оставить только значения 'Attchd' и 'Detchd', остальные заменить на 'Other'\n",
    "garage_mapping = {'Attchd': 'Attchd', 'Detchd': 'Detchd', 'BuiltIn': 'Other', 'Basment': 'Other',\n",
    "    '2Types': 'Other', 'CarPort': 'Other'}\n",
    "subm_df['GarageType'] = subm_df['GarageType'].map(garage_mapping)\n",
    "subm_df['GarageType'] = subm_df['GarageType'].fillna('Other')\n",
    "\n",
    "\n",
    "# Перекодирование колонки 'GarageCars' на 1 или 0\n",
    "subm_df['GarageCars'] = subm_df['GarageCars'].apply(lambda x: 1 if x == 1 else 2 if x == 2 else 3 if x > 2 else 0)\n",
    "# Перекодирование колонки 'OpenPorchSF' на 1 или 0\n",
    "subm_df['OpenPorchSF'] = subm_df['OpenPorchSF'].apply(lambda x: 0 if x == 0 else 1)\n",
    "# # Перекодирование колонки 'WoodDeckSF' на 1 или 0\n",
    "# subm_df['WoodDeckSF'] = subm_df['WoodDeckSF'].apply(lambda x: 0 if x == 0 else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "subm_df = pd.get_dummies(subm_df, columns=col_2_encoding)\n",
    "# # Применяем StandartScaler: после его применения у всех колонок среднее станет равно 0, стандартное отклонение 1\n",
    "# ss_scaler = StandardScaler()\n",
    "# subm_df[col_2_normalize] = ss_scaler.fit_transform(subm_df[col_2_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df['GarageYrBlt'] = subm_df['GarageYrBlt'].fillna(subm_df['GarageYrBlt'].mean())\n",
    "\n",
    "col_2_normalize = ['FullBath', '1stFlrSF', 'GrLivArea', 'TotRmsAbvGrd', 'GarageYrBlt', 'GarageArea',\n",
    "                   'BedroomAbvGr', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
    "                        'YearBuilt', 'YearRemodAdd', 'ExterQual', 'ExterCond', 'BsmtFinSF1',\n",
    "                        'BsmtUnfSF', 'TotalBsmtSF','BsmtQual']\n",
    "\n",
    "for col in col_2_normalize:\n",
    "    subm_df[col] = (subm_df[col] - subm_df[col].min()) / (subm_df[col].max() - subm_df[col].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath', 'KitchenQual', 'GarageArea']: \n",
    "    subm_df[col].fillna(0, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                   0\n",
       "MSSubClass           0\n",
       "MSZoning             0\n",
       "LotFrontage          0\n",
       "LotArea              0\n",
       "LotShape             0\n",
       "LandContour          0\n",
       "LotConfig            0\n",
       "Condition1           0\n",
       "BldgType             0\n",
       "HouseStyle           0\n",
       "OverallQual          0\n",
       "OverallCond          0\n",
       "YearBuilt            0\n",
       "YearRemodAdd         0\n",
       "RoofStyle            0\n",
       "Exterior1st          0\n",
       "Exterior2nd          0\n",
       "MasVnrType           0\n",
       "MasVnrArea           0\n",
       "ExterQual            0\n",
       "ExterCond            0\n",
       "Foundation           0\n",
       "BsmtQual             0\n",
       "BsmtCond             0\n",
       "BsmtExposure         0\n",
       "BsmtFinType1         0\n",
       "BsmtFinSF1           0\n",
       "BsmtFinType2         0\n",
       "BsmtFinSF2           0\n",
       "BsmtUnfSF            0\n",
       "TotalBsmtSF          0\n",
       "HeatingQC            0\n",
       "1stFlrSF             0\n",
       "GrLivArea            0\n",
       "BsmtFullBath         0\n",
       "FullBath             0\n",
       "HalfBath             0\n",
       "BedroomAbvGr         0\n",
       "KitchenQual          0\n",
       "TotRmsAbvGrd         0\n",
       "Fireplaces           0\n",
       "FireplaceQu          0\n",
       "GarageYrBlt          0\n",
       "GarageCars           0\n",
       "GarageArea           0\n",
       "OpenPorchSF          0\n",
       "SaleCondition        0\n",
       "GarageType_Attchd    0\n",
       "GarageType_Detchd    0\n",
       "GarageType_Other     0\n",
       "GarageFinish_Fin     0\n",
       "GarageFinish_RFn     0\n",
       "GarageFinish_Unf     0\n",
       "MoSold_1             0\n",
       "MoSold_2             0\n",
       "MoSold_3             0\n",
       "MoSold_4             0\n",
       "MoSold_5             0\n",
       "MoSold_6             0\n",
       "MoSold_7             0\n",
       "MoSold_8             0\n",
       "MoSold_9             0\n",
       "MoSold_10            0\n",
       "MoSold_11            0\n",
       "MoSold_12            0\n",
       "YrSold_2006          0\n",
       "YrSold_2007          0\n",
       "YrSold_2008          0\n",
       "YrSold_2009          0\n",
       "YrSold_2010          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1071,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2919, 71),\n",
       " array([dtype('int64'), dtype('float64'), dtype('bool')], dtype=object))"
      ]
     },
     "execution_count": 1072,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_df.shape, subm_df.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=subm_df.iloc[:1460,:]\n",
    "X_test=subm_df.iloc[1460:,:]\n",
    "X_test_id = X_test['Id']\n",
    "# df_Test.drop(['SalePrice'],axis=1,inplace=True)\n",
    "# X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "# y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 71), (1459, 71))"
      ]
     },
     "execution_count": 1074,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor()\n",
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 200, 300]\n",
    "max_depth = [2, 3, 5, 7]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "# min_child_weight=[1,2,3,4]\n",
    "\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    # 'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_squared_error',\n",
    "            n_jobs = -1,\n",
    "            verbose = 5,\n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 71), (1459, 71))"
      ]
     },
     "execution_count": 1078,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([dtype('int64'), dtype('float64'), dtype('bool')], dtype=object),\n",
       " array([dtype('int64'), dtype('float64'), dtype('bool')], dtype=object))"
      ]
     },
     "execution_count": 1079,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes.unique(), X_test.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 71), (1459, 71), (1459,))"
      ]
     },
     "execution_count": 1080,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_test_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "# надо разобраться, так делать нельзя\n",
    "X_train = X_train.select_dtypes(include = ['float64', 'int64', 'bool'])\n",
    "X_test = X_test.select_dtypes(include = ['float64', 'int64', 'bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 71), (1459, 71), (1459,))"
      ]
     },
     "execution_count": 1082,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_test_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                   0\n",
       "MSSubClass           0\n",
       "MSZoning             0\n",
       "LotFrontage          0\n",
       "LotArea              0\n",
       "LotShape             0\n",
       "LandContour          0\n",
       "LotConfig            0\n",
       "Condition1           0\n",
       "BldgType             0\n",
       "HouseStyle           0\n",
       "OverallQual          0\n",
       "OverallCond          0\n",
       "YearBuilt            0\n",
       "YearRemodAdd         0\n",
       "RoofStyle            0\n",
       "Exterior1st          0\n",
       "Exterior2nd          0\n",
       "MasVnrType           0\n",
       "MasVnrArea           0\n",
       "ExterQual            0\n",
       "ExterCond            0\n",
       "Foundation           0\n",
       "BsmtQual             0\n",
       "BsmtCond             0\n",
       "BsmtExposure         0\n",
       "BsmtFinType1         0\n",
       "BsmtFinSF1           0\n",
       "BsmtFinType2         0\n",
       "BsmtFinSF2           0\n",
       "BsmtUnfSF            0\n",
       "TotalBsmtSF          0\n",
       "HeatingQC            0\n",
       "1stFlrSF             0\n",
       "GrLivArea            0\n",
       "BsmtFullBath         0\n",
       "FullBath             0\n",
       "HalfBath             0\n",
       "BedroomAbvGr         0\n",
       "KitchenQual          0\n",
       "TotRmsAbvGrd         0\n",
       "Fireplaces           0\n",
       "FireplaceQu          0\n",
       "GarageYrBlt          0\n",
       "GarageCars           0\n",
       "GarageArea           0\n",
       "OpenPorchSF          0\n",
       "SaleCondition        0\n",
       "GarageType_Attchd    0\n",
       "GarageType_Detchd    0\n",
       "GarageType_Other     0\n",
       "GarageFinish_Fin     0\n",
       "GarageFinish_RFn     0\n",
       "GarageFinish_Unf     0\n",
       "MoSold_1             0\n",
       "MoSold_2             0\n",
       "MoSold_3             0\n",
       "MoSold_4             0\n",
       "MoSold_5             0\n",
       "MoSold_6             0\n",
       "MoSold_7             0\n",
       "MoSold_8             0\n",
       "MoSold_9             0\n",
       "MoSold_10            0\n",
       "MoSold_11            0\n",
       "MoSold_12            0\n",
       "YrSold_2006          0\n",
       "YrSold_2007          0\n",
       "YrSold_2008          0\n",
       "YrSold_2009          0\n",
       "YrSold_2010          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1083,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Линейные способы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(X_train.corr(), annot=True, fmt='.2f');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 72)"
      ]
     },
     "execution_count": 1085,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Xy = pd.concat([X_train, y_train], axis=1)\n",
    "df_Xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_Xy.corr()['SalePrice'][:-1].sort_values(key=lambda x: abs(x), ascending=False)\n",
    "# Set the option to display all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "# corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число NaN: 0\n",
      "Число уникальный значений: 6\n",
      "FireplaceQu\n",
      "0.0    1420\n",
      "4.0     744\n",
      "3.0     592\n",
      "2.0      74\n",
      "1.0      46\n",
      "5.0      43\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_analytics('FireplaceQu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OverallQual', 'GrLivArea', 'ExterQual', 'KitchenQual', 'BsmtQual', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'FireplaceQu', 'YearRemodAdd', 'Foundation', 'Fireplaces', 'GarageYrBlt', 'HeatingQC', 'GarageFinish_Fin', 'OpenPorchSF', 'GarageFinish_Unf', 'BsmtFinSF1', 'MasVnrArea', 'GarageType_Detchd', 'GarageType_Attchd', 'LotFrontage', 'MasVnrType', 'HalfBath', 'Exterior1st', 'LotShape', 'LotArea', 'BsmtExposure', 'Exterior2nd', 'MSZoning', 'BsmtFullBath', 'RoofStyle', 'BsmtUnfSF', 'GarageFinish_RFn', 'BedroomAbvGr', 'BsmtFinType1', 'BldgType', 'BsmtFinType2', 'Condition1', 'BsmtCond']\n"
     ]
    }
   ],
   "source": [
    "def get_high_corr_columns(corr_series, threshold):\n",
    "    high_corr_columns = corr_series[abs(corr_series) > threshold].index.tolist()\n",
    "    return high_corr_columns\n",
    "\n",
    "threshold = 0.1  # Adjust the threshold as per your requirement\n",
    "high_corr_columns = get_high_corr_columns(corr, threshold)\n",
    "print(high_corr_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 71), (1459, 71), (1459,))"
      ]
     },
     "execution_count": 1089,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_test_id.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Деревянные способы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permutation importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with higher importance than 'random': ['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'BsmtFinSF1', '1stFlrSF', 'GarageCars', 'YearBuilt', 'GarageArea', 'LotArea', 'YearRemodAdd', 'TotRmsAbvGrd', 'OverallCond', 'BsmtQual', 'LotFrontage', 'KitchenQual', 'Id', 'GarageYrBlt', 'BsmtUnfSF']\n",
      "Columns with lower importance than 'random': ['random', 'FireplaceQu', 'BedroomAbvGr', 'GarageType_Detchd', 'FullBath', 'LotShape', 'BsmtExposure', 'SaleCondition', 'ExterQual', 'MSSubClass', 'HalfBath', 'GarageFinish_Unf', 'HeatingQC', 'Exterior2nd', 'MSZoning', 'MasVnrType', 'LandContour', 'MoSold_7', 'GarageType_Attchd', 'YrSold_2007', 'MoSold_3', 'MoSold_8', 'OpenPorchSF', 'BsmtFullBath', 'ExterCond', 'GarageFinish_RFn', 'Exterior1st', 'Foundation', 'YrSold_2009', 'Condition1', 'Fireplaces', 'MoSold_11', 'RoofStyle', 'MoSold_10', 'BsmtFinType1', 'MasVnrArea', 'GarageFinish_Fin', 'MoSold_6', 'LotConfig', 'YrSold_2008', 'HouseStyle', 'GarageType_Other', 'YrSold_2006', 'YrSold_2010', 'BldgType', 'BsmtCond', 'MoSold_4', 'MoSold_12', 'MoSold_5', 'BsmtFinType2', 'MoSold_9', 'MoSold_1', 'BsmtFinSF2', 'MoSold_2']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train['random'] = np.random.uniform(0,100, size=X_train.shape[0])\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(X_train, y_train, test_size=0.2)\n",
    "r = permutation_importance(rf, x_te, y_te, n_repeats=30, random_state=0)\n",
    "\n",
    "permutation_importances = pd.Series(dict(zip(X_train.columns, r['importances_mean']))).sort_values(key=lambda x: abs(x), ascending=False)\n",
    "\n",
    "# Separate columns with higher and lower importances than the 'random' column\n",
    "higher_importance_columns = permutation_importances[permutation_importances > permutation_importances['random']].index.tolist()\n",
    "lower_importance_columns = permutation_importances[permutation_importances <= permutation_importances['random']].index.tolist()\n",
    "\n",
    "# Print or use the lists as needed\n",
    "print(\"Columns with higher importance than 'random':\", higher_importance_columns)\n",
    "print(\"Columns with lower importance than 'random':\", lower_importance_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сокращаем датасет за счет малозначимых фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 72), (1459, 71))"
      ]
     },
     "execution_count": 1091,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убираем факторы с низкой корреляцией (линейный способ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.iloc[:, high_corr_columns]\n",
    "# X_test = X_test.iloc[:, high_corr_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или убираем факторы с малой значимостию для RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 18), (1459, 18))"
      ]
     },
     "execution_count": 1093,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.loc[:, higher_importance_columns]\n",
    "X_test = X_test.loc[:, higher_importance_columns]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log = np.log(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:02:35] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=200;, score=(train=-0.264, test=-0.390) total time=   0.2s\n",
      "[13:02:35] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:35] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.553, test=-0.536) total time=   0.2s\n",
      "[13:02:35] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=200;, score=(train=-0.263, test=-0.283) total time=   0.2s\n",
      "[13:02:35] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.569, test=-0.903) total time=   0.2s\n",
      "[13:02:35] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=200;, score=(train=-0.338, test=-0.588) total time=   0.2s\n",
      "[13:02:35] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=200;, score=(train=-0.331, test=-0.359) total time=   0.2s\n",
      "[13:02:35] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=200;, score=(train=-0.334, test=-0.282) total time=   0.2s\n",
      "[13:02:36] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=200;, score=(train=-0.332, test=-0.334) total time=   0.2s\n",
      "[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=200;, score=(train=-0.327, test=-0.433) total time=   0.2s\n",
      "[13:02:36] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=200;, score=(train=-0.265, test=-0.259) total time=   0.3s\n",
      "[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=300;, score=(train=-0.000, test=-0.017) total time=   2.0s\n",
      "[13:02:38] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:38] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:38] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=200;, score=(train=-0.264, test=-0.232) total time=   0.2s\n",
      "[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=200;, score=(train=-0.257, test=-0.324) total time=   0.3s\n",
      "[13:02:38] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:38] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:39] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=300;, score=(train=-0.000, test=-0.026) total time=   2.7s\n",
      "[13:02:39] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.567, test=-0.638) total time=   0.8s\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.496, test=-0.991) total time=   0.3s\n",
      "[13:02:39] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.483, test=-0.528) total time=   0.3s\n",
      "[13:02:39] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.566, test=-0.428) total time=   0.5s\n",
      "[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.571, test=-1.272) total time=   0.5s\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.483, test=-0.394) total time=   0.3s\n",
      "[13:02:39] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:39] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.478, test=-0.483) total time=   0.3s\n",
      "[13:02:39] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=100;, score=(train=-0.282, test=-0.473) total time=   0.1s\n",
      "[13:02:39] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=100;, score=(train=-0.277, test=-0.303) total time=   0.1s\n",
      "[13:02:39] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:39] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=100;, score=(train=-0.280, test=-0.233) total time=   0.2s\n",
      "[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=100;, score=(train=-0.273, test=-0.363) total time=   0.1s\n",
      "[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=300;, score=(train=-0.000, test=-0.020) total time=   3.2s\n",
      "[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=100;, score=(train=-0.278, test=-0.282) total time=   0.4s\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.481, test=-0.678) total time=   0.7s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=7, n_estimators=100;, score=(train=-0.000, test=-0.020) total time=   1.5s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=7, n_estimators=100;, score=(train=-0.000, test=-0.026) total time=   1.7s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=7, n_estimators=100;, score=(train=-0.000, test=-0.016) total time=   1.5s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=-0.005, test=-0.016) total time=   1.4s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=7, n_estimators=100;, score=(train=-0.000, test=-0.015) total time=   2.2s\n",
      "[13:02:41] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=7, n_estimators=100;, score=(train=-0.001, test=-0.018) total time=   1.8s\n",
      "[13:02:42] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.282, test=-0.473) total time=   0.2s\n",
      "[13:02:42] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.277, test=-0.303) total time=   0.1s\n",
      "[13:02:42] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=-0.004, test=-0.020) total time=   0.6s\n",
      "[13:02:42] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.280, test=-0.233) total time=   0.1s\n",
      "[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.278, test=-0.282) total time=   0.1s[CV 4/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=300;, score=(train=-0.000, test=-0.017) total time=   4.1s\n",
      "\n",
      "[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.273, test=-0.363) total time=   0.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=-0.004, test=-0.024) total time=   1.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=-0.004, test=-0.021) total time=   0.8s\n",
      "[13:02:42] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=300;, score=(train=-0.000, test=-0.021) total time=   3.8s\n",
      "[13:02:42] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=3, n_estimators=300;, score=(train=-0.450, test=-0.897) total time=   0.3s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=-0.004, test=-0.016) total time=   1.1s\n",
      "[13:02:42] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:42] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=3, n_estimators=300;, score=(train=-0.437, test=-0.478) total time=   0.2s\n",
      "[13:02:42] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=3, n_estimators=300;, score=(train=-0.433, test=-0.436) total time=   0.3s\n",
      "[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=3, n_estimators=300;, score=(train=-0.435, test=-0.618) total time=   0.3s\n",
      "[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=3, n_estimators=300;, score=(train=-0.437, test=-0.357) total time=   0.5s\n",
      "[CV 4/5] END base_score=0.75, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.017) total time=   1.8s\n",
      "[CV 2/5] END base_score=0.75, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.027) total time=   2.3s\n",
      "[CV 1/5] END base_score=0.75, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.018) total time=   2.4s\n",
      "[CV 3/5] END base_score=0.75, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.019) total time=   2.8s\n",
      "[CV 1/5] END base_score=0.75, booster=gbtree, learning_rate=0.05, max_depth=3, n_estimators=100;, score=(train=-0.018, test=-0.024) total time=   0.5s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.021) total time=   2.2s\n",
      "[CV 5/5] END base_score=0.75, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.021) total time=   3.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.025) total time=   2.4s\n",
      "[13:02:45] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.016) total time=   2.5s\n",
      "[13:02:45] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.75, booster=gbtree, learning_rate=0.05, max_depth=3, n_estimators=100;, score=(train=-0.018, test=-0.027) total time=   0.5s\n",
      "[13:02:45] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.75, booster=gbtree, learning_rate=0.05, max_depth=3, n_estimators=100;, score=(train=-0.018, test=-0.027) total time=   0.5s\n",
      "[13:02:45] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=-0.526, test=-1.143) total time=   0.1s\n",
      "[13:02:45] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=-0.524, test=-0.395) total time=   0.1s\n",
      "[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=-0.523, test=-0.591) total time=   0.1s\n",
      "[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=-0.511, test=-0.500) total time=   0.1s\n",
      "[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=-0.525, test=-0.822) total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.017) total time=   1.8s\n",
      "[CV 5/5] END base_score=0.75, booster=gbtree, learning_rate=0.05, max_depth=3, n_estimators=100;, score=(train=-0.018, test=-0.027) total time=   0.5s\n",
      "[CV 4/5] END base_score=0.75, booster=gbtree, learning_rate=0.05, max_depth=3, n_estimators=100;, score=(train=-0.019, test=-0.022) total time=   0.6s\n",
      "[13:02:46] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:46] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.278, test=-0.411) total time=   0.2s\n",
      "[13:02:46] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.276, test=-0.297) total time=   0.3s\n",
      "[13:02:46] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.278, test=-0.244) total time=   0.2s\n",
      "[13:02:46] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.270, test=-0.339) total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.278, test=-0.273) total time=   0.2s\n",
      "[13:02:46] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:46] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.473, test=-0.943) total time=   0.2s\n",
      "[13:02:46] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.009, test=-0.017) total time=   1.0s\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.009, test=-0.015) total time=   1.2s\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.459, test=-0.503) total time=   0.3s\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.008, test=-0.021) total time=   1.2s\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.460, test=-0.375) total time=   0.2s\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=2, n_estimators=100;, score=(train=-0.361, test=-0.690) total time=   0.1s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.009, test=-0.016) total time=   1.3s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.008, test=-0.018) total time=   1.3s\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=2, n_estimators=100;, score=(train=-0.351, test=-0.387) total time=   0.2s[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=2, n_estimators=100;, score=(train=-0.354, test=-0.283) total time=   0.1s\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.455, test=-0.459) total time=   0.3s\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=2, n_estimators=100;, score=(train=-0.349, test=-0.493) total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.021) total time=   2.7s\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.457, test=-0.647) total time=   0.3s\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=2, n_estimators=100;, score=(train=-0.349, test=-0.356) total time=   0.1s\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.250, test=-0.270) total time=   0.2s\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.251, test=-0.221) total time=   0.2s\n",
      "[13:02:47] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.251, test=-0.370) total time=   0.2s\n",
      "[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.571, test=-1.272) total time=   0.2s\n",
      "[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.252, test=-0.246) total time=   0.2s\n",
      "[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.244, test=-0.309) total time=   0.2s\n",
      "[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.553, test=-0.536) total time=   0.2s\n",
      "[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.566, test=-0.428) total time=   0.2s\n",
      "[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.569, test=-0.903) total time=   0.2s\n",
      "[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.567, test=-0.638) total time=   0.3s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.016) total time=   0.4s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.023) total time=   0.6s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.001, test=-0.016) total time=   0.7s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.019) total time=   0.6s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.001, test=-0.019) total time=   0.7s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.001, test=-0.017) total time=   0.8s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.001, test=-0.026) total time=   0.8s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.015) total time=   0.4s\n",
      "[13:02:48] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.001, test=-0.022) total time=   0.8s\n",
      "[13:02:48] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=7, n_estimators=100;, score=(train=-0.328, test=-0.552) total time=   0.1s\n",
      "[13:02:48] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=7, n_estimators=100;, score=(train=-0.322, test=-0.352) total time=   0.1s\n",
      "[13:02:48] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=7, n_estimators=100;, score=(train=-0.326, test=-0.271) total time=   0.1s\n",
      "[13:02:48] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.021) total time=   0.4s\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=7, n_estimators=100;, score=(train=-0.318, test=-0.418) total time=   0.1s\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=7, n_estimators=100;, score=(train=-0.323, test=-0.330) total time=   0.2s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100;, score=(train=-0.009, test=-0.016) total time=   0.4s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-0.012, test=-0.028) total time=   0.8s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100;, score=(train=-0.009, test=-0.023) total time=   0.4s\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-0.012, test=-0.025) total time=   0.9s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-0.012, test=-0.027) total time=   1.0s\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-0.012, test=-0.028) total time=   1.0s\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-0.012, test=-0.020) total time=   1.0s\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.630, test=-1.405) total time=   0.3s\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.626, test=-0.705) total time=   0.2s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100;, score=(train=-0.010, test=-0.017) total time=   0.4s\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.625, test=-0.474) total time=   0.2s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100;, score=(train=-0.009, test=-0.019) total time=   0.7s\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100;, score=(train=-0.009, test=-0.018) total time=   0.4s\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.611, test=-0.593) total time=   0.2s\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=2, n_estimators=200;, score=(train=-0.600, test=-1.337) total time=   0.2s\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.629, test=-0.992) total time=   0.3s\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=2, n_estimators=200;, score=(train=-0.595, test=-0.450) total time=   0.3s\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=2, n_estimators=200;, score=(train=-0.596, test=-0.671) total time=   0.3s\n",
      "[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.274, test=-0.407) total time=   0.3s\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=2, n_estimators=200;, score=(train=-0.582, test=-0.564) total time=   0.3s\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=2, n_estimators=200;, score=(train=-0.599, test=-0.947) total time=   0.3s\n",
      "[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.274, test=-0.243) total time=   0.2s\n",
      "[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.273, test=-0.293) total time=   0.4s\n",
      "[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.275, test=-0.268) total time=   0.3s\n",
      "[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.267, test=-0.335) total time=   0.3s\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, n_estimators=100;, score=(train=-0.023, test=-0.030) total time=   0.3s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, n_estimators=100;, score=(train=-0.024, test=-0.024) total time=   0.3s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, n_estimators=100;, score=(train=-0.024, test=-0.032) total time=   0.4s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, n_estimators=100;, score=(train=-0.024, test=-0.026) total time=   0.5s\n",
      "[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.016) total time=   0.3s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, n_estimators=100;, score=(train=-0.023, test=-0.029) total time=   0.5s\n",
      "[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.012, test=-0.021) total time=   0.3s\n",
      "[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.019) total time=   0.3s\n",
      "[CV 4/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.017) total time=   0.3s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.016) total time=   0.3s\n",
      "[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.019) total time=   0.4s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.022) total time=   0.4s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.020) total time=   0.4s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.018) total time=   0.4s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.019) total time=   0.5s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, n_estimators=200;, score=(train=-0.009, test=-0.021) total time=   0.5s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, n_estimators=200;, score=(train=-0.008, test=-0.015) total time=   0.6s\n",
      "[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.007, test=-0.023) total time=   0.7s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, n_estimators=200;, score=(train=-0.008, test=-0.018) total time=   0.8s\n",
      "[13:02:51] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:51] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, n_estimators=200;, score=(train=-0.009, test=-0.017) total time=   0.8s\n",
      "[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.008, test=-0.015) total time=   0.8s\n",
      "[13:02:51] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, n_estimators=200;, score=(train=-0.009, test=-0.015) total time=   0.9s\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=100;, score=(train=-0.409, test=-0.451) total time=   0.1s\n",
      "\n",
      "[13:02:51] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:51] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.007, test=-0.018) total time=   0.7s\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=100;, score=(train=-0.407, test=-0.568) total time=   0.1s\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=100;, score=(train=-0.420, test=-0.805) total time=   0.2s\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=100;, score=(train=-0.406, test=-0.416) total time=   0.1s\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=100;, score=(train=-0.412, test=-0.331) total time=   0.2s\n",
      "[CV 4/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.007, test=-0.015) total time=   0.8s\n",
      "[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.008, test=-0.018) total time=   0.8s\n",
      "[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.016) total time=   0.7s\n",
      "[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.024) total time=   0.6s\n",
      "[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.019) total time=   0.4s\n",
      "[13:02:52] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.019) total time=   0.9s\n",
      "[13:02:52] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.213, test=-0.292) total time=   0.2s\n",
      "[13:02:53] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=300;, score=(train=-0.002, test=-0.020) total time=   1.5s\n",
      "[13:02:53] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.213, test=-0.190) total time=   0.2s\n",
      "[CV 4/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.016) total time=   0.8s\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.212, test=-0.229) total time=   0.4s[13:02:53] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.214, test=-0.205) total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=300;, score=(train=-0.002, test=-0.016) total time=   1.8s\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.206, test=-0.260) total time=   0.3s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=300;, score=(train=-0.001, test=-0.019) total time=   1.9s\n",
      "[13:02:53] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=300;, score=(train=-0.002, test=-0.016) total time=   1.9s\n",
      "[13:02:53] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=300;, score=(train=-0.002, test=-0.022) total time=   2.0s\n",
      "[13:02:53] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.542, test=-1.208) total time=   0.3s\n",
      "[13:02:53] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.538, test=-0.606) total time=   0.3s\n",
      "[13:02:53] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.537, test=-0.406) total time=   0.4s\n",
      "[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.526, test=-0.508) total time=   0.2s\n",
      "[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.540, test=-0.860) total time=   0.4s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.020) total time=   2.0s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.019) total time=   2.4s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.025) total time=   3.4s\n",
      "[13:02:56] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.021) total time=   3.3s\n",
      "[13:02:56] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.002, test=-0.024) total time=   2.8s\n",
      "[13:02:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=7, n_estimators=200;, score=(train=-0.291, test=-0.432) total time=   0.3s\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=7, n_estimators=200;, score=(train=-0.290, test=-0.312) total time=   0.3s\n",
      "[13:02:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:02:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.003, test=-0.017) total time=   3.1s\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=7, n_estimators=200;, score=(train=-0.284, test=-0.354) total time=   0.2s\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=7, n_estimators=200;, score=(train=-0.291, test=-0.256) total time=   0.3s\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=7, n_estimators=200;, score=(train=-0.292, test=-0.287) total time=   0.3s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.016) total time=   4.1s\n",
      "[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.002, test=-0.020) total time=   3.2s\n",
      "[CV 4/5] END base_score=1, booster=gbtree, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.002, test=-0.015) total time=   2.7s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=300;, score=(train=-0.004, test=-0.015) total time=   1.4s\n",
      "[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.002, test=-0.018) total time=   3.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=300;, score=(train=-0.004, test=-0.021) total time=   1.9s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=300;, score=(train=-0.004, test=-0.023) total time=   2.3s\n",
      "[13:02:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=300;, score=(train=-0.004, test=-0.019) total time=   2.2s\n",
      "[13:02:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=300;, score=(train=-0.004, test=-0.015) total time=   2.4s\n",
      "[13:02:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.303, test=-0.451) total time=   0.3s\n",
      "[13:02:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.301, test=-0.324) total time=   0.3s\n",
      "[13:02:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.001, test=-0.016) total time=   2.6s\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.303, test=-0.268) total time=   0.4s\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.295, test=-0.367) total time=   0.5s\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.303, test=-0.298) total time=   0.6s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.001, test=-0.025) total time=   3.0s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.001, test=-0.016) total time=   2.4s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.001, test=-0.020) total time=   2.8s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.017) total time=   2.1s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.020) total time=   2.0s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.022) total time=   1.4s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.024) total time=   2.3s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.001, test=-0.021) total time=   3.2s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.016) total time=   2.3s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.017) total time=   1.7s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.026) total time=   2.6s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.020) total time=   2.0s\n",
      "[13:03:04] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.019) total time=   1.9s\n",
      "[13:03:04] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.016) total time=   1.9s\n",
      "[13:03:04] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=300;, score=(train=-0.227, test=-0.307) total time=   0.3s\n",
      "[13:03:04] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.019) total time=   1.9s\n",
      "[13:03:04] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=300;, score=(train=-0.228, test=-0.218) total time=   0.3s\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=300;, score=(train=-0.226, test=-0.243) total time=   0.4s\n",
      "[13:03:04] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.001, test=-0.026) total time=   2.2s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.017) total time=   2.4s\n",
      "[13:03:04] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:04] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:04] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.328, test=-0.552) total time=   0.1s\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=300;, score=(train=-0.226, test=-0.205) total time=   0.4s\n",
      "[13:03:05] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:05] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.323, test=-0.330) total time=   0.2s\n",
      "[13:03:05] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.326, test=-0.271) total time=   0.2s\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.322, test=-0.352) total time=   0.2s\n",
      "[13:03:05] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:05] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.318, test=-0.418) total time=   0.2s\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=300;, score=(train=-0.220, test=-0.273) total time=   0.4s\n",
      "[13:03:05] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-1.041, test=-2.107) total time=   0.2s\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-1.119, test=-1.322) total time=   0.2s\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-1.143, test=-0.838) total time=   0.2s\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-1.131, test=-1.791) total time=   0.1s\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-1.122, test=-0.946) total time=   0.2s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.016) total time=   2.2s\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.001, test=-0.019) total time=   1.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, gpu_id=None,\n",
       "                                          grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=...\n",
       "                                          n_estimators=100, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          predictor=None, random_state=None, ...),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;base_score&#x27;: [0.25, 0.5, 0.75, 1],\n",
       "                                        &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;],\n",
       "                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2],\n",
       "                                        &#x27;max_depth&#x27;: [2, 3, 5, 7],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring=&#x27;neg_mean_squared_error&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, gpu_id=None,\n",
       "                                          grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=...\n",
       "                                          n_estimators=100, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          predictor=None, random_state=None, ...),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;base_score&#x27;: [0.25, 0.5, 0.75, 1],\n",
       "                                        &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;],\n",
       "                                        &#x27;learning_rate&#x27;: [0.05, 0.1, 0.15, 0.2],\n",
       "                                        &#x27;max_depth&#x27;: [2, 3, 5, 7],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring=&#x27;neg_mean_squared_error&#x27;, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, gpu_id=None,\n",
       "                                          grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=...\n",
       "                                          n_estimators=100, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          predictor=None, random_state=None, ...),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
       "                                        'max_depth': [2, 3, 5, 7],\n",
       "                                        'n_estimators': [100, 200, 300]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 1095,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_cv.fit(X_train,y_train)\n",
    "random_cv.fit(X_train,y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def get_score(model, X, y):\n",
    "    model.fit(X, y.ravel())\n",
    "\n",
    "    # Получаем предсказания на тестовых данных\n",
    "    y_pred = (model.predict(X))\n",
    "    # y_pred = np.exp(model.predict(X))\n",
    "\n",
    "    # Вычисляем среднеквадратическую ошибку (MSE)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "\n",
    "    # Получаем корень из MSE, чтобы получить RMSE\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return f'Значение метрики RMSE: {rmse}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import f_regression, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=200;, score=(train=-0.264, test=-0.390) total time=   0.1s\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=200;, score=(train=-0.263, test=-0.283) total time=   0.1s\n",
      "[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.571, test=-1.272) total time=   0.2s\n",
      "[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=200;, score=(train=-0.264, test=-0.232) total time=   0.1s\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=200;, score=(train=-0.265, test=-0.259) total time=   0.2s\n",
      "[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=200;, score=(train=-0.257, test=-0.324) total time=   0.2s\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.567, test=-0.638) total time=   0.2s\n",
      "[13:03:49] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.553, test=-0.536) total time=   0.2s\n",
      "[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.569, test=-0.903) total time=   0.1s\n",
      "[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=200;, score=(train=-0.338, test=-0.588) total time=   0.2s\n",
      "[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.566, test=-0.428) total time=   0.3s\n",
      "[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=200;, score=(train=-0.331, test=-0.359) total time=   0.2s\n",
      "[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=200;, score=(train=-0.332, test=-0.334) total time=   0.2s\n",
      "[13:03:50] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=200;, score=(train=-0.334, test=-0.282) total time=   0.2s\n",
      "[13:03:50] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:50] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:50] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=200;, score=(train=-0.327, test=-0.433) total time=   0.2s\n",
      "[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=100;, score=(train=-0.277, test=-0.303) total time=   0.1s\n",
      "[13:03:50] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:50] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=100;, score=(train=-0.280, test=-0.233) total time=   0.1s\n",
      "[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=100;, score=(train=-0.278, test=-0.282) total time=   0.1s\n",
      "[13:03:50] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=100;, score=(train=-0.273, test=-0.363) total time=   0.1s\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.483, test=-0.394) total time=   0.4s\n",
      "[13:03:50] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.496, test=-0.991) total time=   0.5s\n",
      "[13:03:50] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.481, test=-0.678) total time=   0.5s\n",
      "[13:03:50] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=100;, score=(train=-0.282, test=-0.473) total time=   0.2s\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.478, test=-0.483) total time=   0.4s\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.483, test=-0.528) total time=   0.4s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=7, n_estimators=100;, score=(train=-0.000, test=-0.015) total time=   0.9s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=7, n_estimators=100;, score=(train=-0.000, test=-0.020) total time=   1.1s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=-0.004, test=-0.024) total time=   0.6s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=-0.004, test=-0.016) total time=   0.6s\n",
      "[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=300;, score=(train=-0.000, test=-0.026) total time=   1.7s\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=7, n_estimators=100;, score=(train=-0.001, test=-0.018) total time=   1.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=-0.004, test=-0.020) total time=   0.5s\n",
      "[13:03:52] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.282, test=-0.473) total time=   0.1s\n",
      "[13:03:52] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.277, test=-0.303) total time=   0.1s\n",
      "[13:03:52] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=-0.004, test=-0.021) total time=   0.7s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=7, n_estimators=100;, score=(train=-0.000, test=-0.026) total time=   1.2s\n",
      "[13:03:52] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=300;, score=(train=-0.000, test=-0.017) total time=   2.5s\n",
      "[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.273, test=-0.363) total time=   0.2s\n",
      "[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.280, test=-0.233) total time=   0.2s\n",
      "[13:03:52] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=7, n_estimators=100;, score=(train=-0.000, test=-0.016) total time=   1.2s\n",
      "[13:03:52] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.278, test=-0.282) total time=   0.2s\n",
      "[13:03:52] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=100;, score=(train=-0.005, test=-0.016) total time=   0.9s\n",
      "[13:03:52] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=300;, score=(train=-0.000, test=-0.017) total time=   3.0s\n",
      "[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=3, n_estimators=300;, score=(train=-0.450, test=-0.897) total time=   0.5s\n",
      "[13:03:53] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=3, n_estimators=300;, score=(train=-0.435, test=-0.618) total time=   0.5s\n",
      "[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=3, n_estimators=300;, score=(train=-0.437, test=-0.357) total time=   0.6s\n",
      "[13:03:53] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=300;, score=(train=-0.000, test=-0.020) total time=   1.6s\n",
      "[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=3, n_estimators=300;, score=(train=-0.437, test=-0.478) total time=   0.3s\n",
      "[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=3, n_estimators=300;, score=(train=-0.433, test=-0.436) total time=   0.4s\n",
      "[CV 1/5] END base_score=0.75, booster=gbtree, learning_rate=0.05, max_depth=3, n_estimators=100;, score=(train=-0.018, test=-0.024) total time=   0.5s\n",
      "[CV 2/5] END base_score=0.75, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.027) total time=   2.4s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.025) total time=   1.5s\n",
      "[CV 4/5] END base_score=0.75, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.017) total time=   2.4s\n",
      "[CV 2/5] END base_score=0.75, booster=gbtree, learning_rate=0.05, max_depth=3, n_estimators=100;, score=(train=-0.018, test=-0.027) total time=   0.6s\n",
      "[CV 1/5] END base_score=0.75, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.018) total time=   2.5s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.016) total time=   1.9s\n",
      "[13:03:55] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=-0.523, test=-0.591) total time=   0.1s\n",
      "[13:03:55] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=-0.524, test=-0.395) total time=   0.1s\n",
      "[13:03:55] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=-0.511, test=-0.500) total time=   0.1s\n",
      "[CV 3/5] END base_score=0.75, booster=gbtree, learning_rate=0.05, max_depth=3, n_estimators=100;, score=(train=-0.018, test=-0.027) total time=   0.6s\n",
      "[13:03:55] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.017) total time=   1.9s\n",
      "[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=-0.525, test=-0.822) total time=   0.1s\n",
      "[CV 5/5] END base_score=0.75, booster=gbtree, learning_rate=0.05, max_depth=3, n_estimators=100;, score=(train=-0.018, test=-0.027) total time=   0.6s\n",
      "[13:03:55] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.1, max_depth=7, n_estimators=100;, score=(train=-0.526, test=-1.143) total time=   0.1s\n",
      "[CV 4/5] END base_score=0.75, booster=gbtree, learning_rate=0.05, max_depth=3, n_estimators=100;, score=(train=-0.019, test=-0.022) total time=   0.4s\n",
      "[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=300;, score=(train=-0.000, test=-0.021) total time=   2.9s\n",
      "[13:03:55] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.276, test=-0.297) total time=   0.2s\n",
      "[13:03:56] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.021) total time=   1.4s\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.278, test=-0.244) total time=   0.2s\n",
      "[13:03:56] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:56] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.75, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.021) total time=   1.6s\n",
      "[13:03:56] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.278, test=-0.273) total time=   0.2s\n",
      "[13:03:56] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.008, test=-0.018) total time=   0.9s\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.459, test=-0.503) total time=   0.2s\n",
      "[13:03:56] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.473, test=-0.943) total time=   0.4s\n",
      "[13:03:56] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.270, test=-0.339) total time=   0.3s\n",
      "[13:03:56] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.460, test=-0.375) total time=   0.2s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.009, test=-0.015) total time=   1.3s[13:03:56] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "\n",
      "[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=2, n_estimators=100;, score=(train=-0.361, test=-0.690) total time=   0.1s\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.009, test=-0.017) total time=   1.2s\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=2, n_estimators=100;, score=(train=-0.351, test=-0.387) total time=   0.1s\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.455, test=-0.459) total time=   0.5s\n",
      "[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=2, n_estimators=100;, score=(train=-0.354, test=-0.283) total time=   0.1s\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.457, test=-0.647) total time=   0.4s\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.278, test=-0.411) total time=   0.2s\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=2, n_estimators=100;, score=(train=-0.349, test=-0.356) total time=   0.1s\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=2, n_estimators=100;, score=(train=-0.349, test=-0.493) total time=   0.2s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.009, test=-0.016) total time=   0.8s\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.250, test=-0.270) total time=   0.2s\n",
      "[CV 3/5] END base_score=0.75, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.019) total time=   2.7s\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.244, test=-0.309) total time=   0.1s\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.251, test=-0.221) total time=   0.3s\n",
      "[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.251, test=-0.370) total time=   0.3s\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:57] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.252, test=-0.246) total time=   0.2s\n",
      "[CV 2/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.567, test=-0.638) total time=   0.2s\n",
      "[CV 1/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.571, test=-1.272) total time=   0.3s\n",
      "[CV 3/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.566, test=-0.428) total time=   0.2s\n",
      "[CV 5/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.569, test=-0.903) total time=   0.2s\n",
      "[CV 4/5] END base_score=0.75, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.553, test=-0.536) total time=   0.3s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.021) total time=   2.6s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.008, test=-0.021) total time=   1.2s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.001, test=-0.017) total time=   0.5s\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.001, test=-0.022) total time=   0.5s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.001, test=-0.026) total time=   0.7s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.001, test=-0.019) total time=   0.7s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.016) total time=   0.6s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.015) total time=   0.4s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.001, test=-0.016) total time=   0.8s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.019) total time=   0.5s\n",
      "[13:03:58] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.023) total time=   0.6s\n",
      "[13:03:58] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.021) total time=   0.4s\n",
      "[13:03:58] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=7, n_estimators=100;, score=(train=-0.328, test=-0.552) total time=   0.1s\n",
      "[13:03:58] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=7, n_estimators=100;, score=(train=-0.326, test=-0.271) total time=   0.1s\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=7, n_estimators=100;, score=(train=-0.322, test=-0.352) total time=   0.2s\n",
      "[13:03:58] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=7, n_estimators=100;, score=(train=-0.318, test=-0.418) total time=   0.1s\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=7, n_estimators=100;, score=(train=-0.323, test=-0.330) total time=   0.2s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-0.012, test=-0.020) total time=   0.5s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-0.012, test=-0.028) total time=   0.8s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-0.012, test=-0.028) total time=   0.9s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100;, score=(train=-0.009, test=-0.016) total time=   0.4s\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100;, score=(train=-0.009, test=-0.023) total time=   0.4s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100;, score=(train=-0.009, test=-0.019) total time=   0.3s\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-0.012, test=-0.025) total time=   0.8s\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-0.012, test=-0.027) total time=   1.0s\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.630, test=-1.405) total time=   0.2s\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.626, test=-0.705) total time=   0.2s\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.625, test=-0.474) total time=   0.2s\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.629, test=-0.992) total time=   0.2s\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100;, score=(train=-0.010, test=-0.017) total time=   0.6s\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=5, n_estimators=200;, score=(train=-0.611, test=-0.593) total time=   0.3s\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=2, n_estimators=200;, score=(train=-0.600, test=-1.337) total time=   0.2s\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=2, n_estimators=200;, score=(train=-0.582, test=-0.564) total time=   0.1s\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=2, n_estimators=200;, score=(train=-0.596, test=-0.671) total time=   0.3s\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=2, n_estimators=200;, score=(train=-0.595, test=-0.450) total time=   0.2s\n",
      "[13:03:59] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.274, test=-0.407) total time=   0.3s\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=100;, score=(train=-0.009, test=-0.018) total time=   0.6s\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.05, max_depth=2, n_estimators=200;, score=(train=-0.599, test=-0.947) total time=   0.3s\n",
      "[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.275, test=-0.268) total time=   0.3s\n",
      "[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.267, test=-0.335) total time=   0.3s\n",
      "[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.274, test=-0.243) total time=   0.5s\n",
      "[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.273, test=-0.293) total time=   0.5s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, n_estimators=100;, score=(train=-0.024, test=-0.026) total time=   0.4s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, n_estimators=100;, score=(train=-0.023, test=-0.029) total time=   0.3s\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, n_estimators=100;, score=(train=-0.023, test=-0.030) total time=   0.2s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, n_estimators=100;, score=(train=-0.024, test=-0.024) total time=   0.3s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.05, max_depth=2, n_estimators=100;, score=(train=-0.024, test=-0.032) total time=   0.5s\n",
      "[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.019) total time=   0.3s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.016) total time=   0.3s\n",
      "[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.012, test=-0.021) total time=   0.4s\n",
      "[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.016) total time=   0.4s\n",
      "[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.019) total time=   0.4s\n",
      "[CV 4/5] END base_score=1, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.017) total time=   0.4s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.022) total time=   0.4s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.018) total time=   0.3s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.020) total time=   0.4s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=2, n_estimators=100;, score=(train=-0.013, test=-0.019) total time=   0.4s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, n_estimators=200;, score=(train=-0.008, test=-0.018) total time=   0.5s\n",
      "[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.008, test=-0.015) total time=   0.5s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, n_estimators=200;, score=(train=-0.008, test=-0.015) total time=   0.7s\n",
      "[13:04:01] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, n_estimators=200;, score=(train=-0.009, test=-0.021) total time=   0.7s\n",
      "[13:04:01] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.007, test=-0.023) total time=   0.6s\n",
      "[13:04:01] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=100;, score=(train=-0.420, test=-0.805) total time=   0.1s\n",
      "[13:04:01] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=100;, score=(train=-0.409, test=-0.451) total time=   0.1s\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, n_estimators=200;, score=(train=-0.009, test=-0.017) total time=   0.8s\n",
      "[13:04:01] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=100;, score=(train=-0.412, test=-0.331) total time=   0.2s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=2, n_estimators=200;, score=(train=-0.009, test=-0.015) total time=   1.0s\n",
      "[CV 4/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.007, test=-0.015) total time=   0.5s\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=100;, score=(train=-0.407, test=-0.568) total time=   0.1s\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=5, n_estimators=100;, score=(train=-0.406, test=-0.416) total time=   0.2s\n",
      "[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.007, test=-0.018) total time=   0.8s\n",
      "[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.008, test=-0.018) total time=   0.6s\n",
      "[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.016) total time=   0.7s\n",
      "[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.024) total time=   0.7s\n",
      "[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.019) total time=   0.8s\n",
      "[13:04:02] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.213, test=-0.292) total time=   0.4s\n",
      "[CV 4/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.016) total time=   0.6s\n",
      "[13:04:03] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:04:03] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=100;, score=(train=-0.006, test=-0.019) total time=   0.7s\n",
      "[13:04:03] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=300;, score=(train=-0.002, test=-0.016) total time=   1.7s\n",
      "[13:04:03] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=300;, score=(train=-0.002, test=-0.022) total time=   1.7s\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.213, test=-0.190) total time=   0.3s\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.214, test=-0.205) total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.206, test=-0.260) total time=   0.2s\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.2, max_depth=2, n_estimators=200;, score=(train=-0.212, test=-0.229) total time=   0.5s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=300;, score=(train=-0.001, test=-0.019) total time=   2.2s\n",
      "[13:04:04] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=300;, score=(train=-0.002, test=-0.016) total time=   2.3s\n",
      "[13:04:04] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.542, test=-1.208) total time=   0.2s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=3, n_estimators=300;, score=(train=-0.002, test=-0.020) total time=   2.4s\n",
      "[13:04:04] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:04:04] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.538, test=-0.606) total time=   0.3s\n",
      "[13:04:04] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.537, test=-0.406) total time=   0.3s\n",
      "[CV 4/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.526, test=-0.508) total time=   0.3s\n",
      "[CV 5/5] END base_score=1, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=200;, score=(train=-0.540, test=-0.860) total time=   0.2s\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.025) total time=   2.7s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.020) total time=   3.0s\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.021) total time=   3.0s\n",
      "[13:04:06] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=1, booster=gbtree, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.002, test=-0.020) total time=   2.1s\n",
      "[13:04:06] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.016) total time=   3.3s\n",
      "[13:04:07] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=7, n_estimators=200;, score=(train=-0.290, test=-0.312) total time=   0.2s\n",
      "[13:04:07] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=7, n_estimators=200;, score=(train=-0.291, test=-0.432) total time=   0.4s\n",
      "[13:04:07] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.2, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.019) total time=   3.6s\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=7, n_estimators=200;, score=(train=-0.292, test=-0.287) total time=   0.2s\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=7, n_estimators=200;, score=(train=-0.291, test=-0.256) total time=   0.3s\n",
      "[CV 2/5] END base_score=1, booster=gbtree, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.002, test=-0.024) total time=   2.7s\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=7, n_estimators=200;, score=(train=-0.284, test=-0.354) total time=   0.4s\n",
      "[CV 1/5] END base_score=1, booster=gbtree, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.003, test=-0.017) total time=   3.4s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=300;, score=(train=-0.004, test=-0.023) total time=   1.5s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=300;, score=(train=-0.004, test=-0.015) total time=   1.4s\n",
      "[CV 4/5] END base_score=1, booster=gbtree, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.002, test=-0.015) total time=   3.0s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=300;, score=(train=-0.004, test=-0.019) total time=   2.0s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=300;, score=(train=-0.004, test=-0.015) total time=   2.3s\n",
      "[13:04:09] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=3, n_estimators=300;, score=(train=-0.004, test=-0.021) total time=   2.6s\n",
      "[13:04:10] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=1, booster=gbtree, learning_rate=0.05, max_depth=5, n_estimators=300;, score=(train=-0.002, test=-0.018) total time=   3.5s\n",
      "[13:04:10] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.303, test=-0.451) total time=   0.8s\n",
      "[13:04:10] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.301, test=-0.324) total time=   0.4s\n",
      "[13:04:10] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.303, test=-0.268) total time=   0.5s\n",
      "[CV 4/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.303, test=-0.298) total time=   0.5s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.001, test=-0.025) total time=   2.3s\n",
      "[CV 5/5] END base_score=0.5, booster=gblinear, learning_rate=0.1, max_depth=2, n_estimators=300;, score=(train=-0.295, test=-0.367) total time=   0.5s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.001, test=-0.020) total time=   2.3s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.001, test=-0.016) total time=   4.2s\n",
      "[CV 2/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.024) total time=   1.6s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.022) total time=   1.4s\n",
      "[CV 1/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.017) total time=   1.9s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.016) total time=   2.2s\n",
      "[CV 4/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.001, test=-0.016) total time=   4.2s\n",
      "[CV 5/5] END base_score=0.5, booster=gbtree, learning_rate=0.1, max_depth=5, n_estimators=300;, score=(train=-0.001, test=-0.021) total time=   4.7s\n",
      "[CV 3/5] END base_score=0.5, booster=gbtree, learning_rate=0.2, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.020) total time=   3.2s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.020) total time=   2.2s\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.017) total time=   2.7s\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.016) total time=   2.0s\n",
      "[13:04:15] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.026) total time=   3.5s\n",
      "[13:04:16] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.017) total time=   3.8s\n",
      "[13:04:16] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=300;, score=(train=-0.227, test=-0.307) total time=   0.5s\n",
      "[13:04:16] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.016) total time=   1.5s\n",
      "[13:04:16] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=300;, score=(train=-0.226, test=-0.243) total time=   0.4s\n",
      "[13:04:16] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.001, test=-0.026) total time=   2.2s\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=300;, score=(train=-0.226, test=-0.205) total time=   0.4s\n",
      "[13:04:16] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:04:16] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.328, test=-0.552) total time=   0.2s\n",
      "[13:04:16] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=300;, score=(train=-0.228, test=-0.218) total time=   0.4s\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.15, max_depth=3, n_estimators=300;, score=(train=-0.220, test=-0.273) total time=   0.3s\n",
      "[CV 3/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.000, test=-0.019) total time=   2.3s\n",
      "[13:04:16] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:04:16] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.322, test=-0.352) total time=   0.2s\n",
      "[13:04:16] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.326, test=-0.271) total time=   0.2s\n",
      "[13:04:16] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[13:04:16] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 1/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-1.041, test=-2.107) total time=   0.1s\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.323, test=-0.330) total time=   0.1s\n",
      "[13:04:16] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.2, max_depth=5, n_estimators=100;, score=(train=-0.318, test=-0.418) total time=   0.1s\n",
      "[CV 4/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-1.122, test=-0.946) total time=   0.1s\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.1, max_depth=7, n_estimators=200;, score=(train=-0.000, test=-0.019) total time=   3.5s\n",
      "[CV 3/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-1.143, test=-0.838) total time=   0.2s\n",
      "[CV 2/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-1.119, test=-1.322) total time=   0.2s\n",
      "[CV 5/5] END base_score=0.25, booster=gblinear, learning_rate=0.05, max_depth=7, n_estimators=100;, score=(train=-1.131, test=-1.791) total time=   0.1s\n",
      "[CV 5/5] END base_score=0.25, booster=gbtree, learning_rate=0.15, max_depth=5, n_estimators=200;, score=(train=-0.001, test=-0.019) total time=   1.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Значение метрики RMSE: 0.09623926687210206'"
      ]
     },
     "execution_count": 1098,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(random_cv, X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1459, 18), (1460, 18))"
      ]
     },
     "execution_count": 1099,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = (random_cv.predict(X_test))\n",
    "y_pred = np.exp((random_cv.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169894.94, (1459,), (1459,))"
      ]
     },
     "execution_count": 1101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.mean(), y_pred.shape, X_test_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем DataFrame в CSV-файл\n",
    "# df_last_40.to_csv('subm_df_last_40.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_num = df.select_dtypes(include = ['float64', 'int64'])\n",
    "# df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_2_csv(id_column, predictions_column, file_name='submission.csv'):\n",
    "    # Создаем DataFrame из переданных столбцов\n",
    "    df = pd.DataFrame({ 'Id': id_column, 'SalePrice': predictions_column })\n",
    "    # Сохраняем DataFrame в CSV-файл\n",
    "    df.to_csv(file_name, index=False)\n",
    "\n",
    "# # res_2_csv(test['Id'], y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2_csv(X_test_id, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
